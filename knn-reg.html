<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>R for Statistical Learning</title>
  <meta name="description" content="<code>R</code> for Statistical Learning">
  <meta name="generator" content="bookdown 0.5.4 and GitBook 2.6.7">

  <meta property="og:title" content="R for Statistical Learning" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://daviddalpiaz.github.io/r4sl/" />
  
  
  <meta name="github-repo" content="daviddalpiaz/r4sl" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="R for Statistical Learning" />
  
  
  

<meta name="author" content="David Dalpiaz">


<meta name="date" content="2017-11-01">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
<link rel="prev" href="linear-models.html">
<link rel="next" href="biasvariance-tradeoff.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R for Statistical Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i>About This Book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#organization"><i class="fa fa-check"></i>Organization</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who"><i class="fa fa-check"></i>Who?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#caveat-emptor"><i class="fa fa-check"></i>Caveat Emptor</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#conventions"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="part"><span><b>I Prerequisites</b></span></li>
<li class="chapter" data-level="1" data-path="prerequisites-overview.html"><a href="prerequisites-overview.html"><i class="fa fa-check"></i><b>1</b> Overview</a></li>
<li class="chapter" data-level="2" data-path="probability-review.html"><a href="probability-review.html"><i class="fa fa-check"></i><b>2</b> Probability Review</a><ul>
<li class="chapter" data-level="2.1" data-path="probability-review.html"><a href="probability-review.html#probability-models"><i class="fa fa-check"></i><b>2.1</b> Probability Models</a></li>
<li class="chapter" data-level="2.2" data-path="probability-review.html"><a href="probability-review.html#probability-axioms"><i class="fa fa-check"></i><b>2.2</b> Probability Axioms</a></li>
<li class="chapter" data-level="2.3" data-path="probability-review.html"><a href="probability-review.html#probability-rules"><i class="fa fa-check"></i><b>2.3</b> Probability Rules</a></li>
<li class="chapter" data-level="2.4" data-path="probability-review.html"><a href="probability-review.html#random-variables"><i class="fa fa-check"></i><b>2.4</b> Random Variables</a><ul>
<li class="chapter" data-level="2.4.1" data-path="probability-review.html"><a href="probability-review.html#distributions"><i class="fa fa-check"></i><b>2.4.1</b> Distributions</a></li>
<li class="chapter" data-level="2.4.2" data-path="probability-review.html"><a href="probability-review.html#discrete-random-variables"><i class="fa fa-check"></i><b>2.4.2</b> Discrete Random Variables</a></li>
<li class="chapter" data-level="2.4.3" data-path="probability-review.html"><a href="probability-review.html#continuous-random-variables"><i class="fa fa-check"></i><b>2.4.3</b> Continuous Random Variables</a></li>
<li class="chapter" data-level="2.4.4" data-path="probability-review.html"><a href="probability-review.html#several-random-variables"><i class="fa fa-check"></i><b>2.4.4</b> Several Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="probability-review.html"><a href="probability-review.html#expectations"><i class="fa fa-check"></i><b>2.5</b> Expectations</a></li>
<li class="chapter" data-level="2.6" data-path="probability-review.html"><a href="probability-review.html#likelihood"><i class="fa fa-check"></i><b>2.6</b> Likelihood</a></li>
<li class="chapter" data-level="2.7" data-path="probability-review.html"><a href="probability-review.html#videos"><i class="fa fa-check"></i><b>2.7</b> Videos</a></li>
<li class="chapter" data-level="2.8" data-path="probability-review.html"><a href="probability-review.html#references"><i class="fa fa-check"></i><b>2.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="r-rstudio-rmarkdown.html"><a href="r-rstudio-rmarkdown.html"><i class="fa fa-check"></i><b>3</b> <code>R</code>, RStudio, RMarkdown</a><ul>
<li class="chapter" data-level="3.1" data-path="r-rstudio-rmarkdown.html"><a href="r-rstudio-rmarkdown.html#videos-1"><i class="fa fa-check"></i><b>3.1</b> Videos</a></li>
<li class="chapter" data-level="3.2" data-path="r-rstudio-rmarkdown.html"><a href="r-rstudio-rmarkdown.html#template"><i class="fa fa-check"></i><b>3.2</b> Template</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html"><i class="fa fa-check"></i><b>4</b> Modeling Basics in <code>R</code></a><ul>
<li class="chapter" data-level="4.1" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#visualization-for-regression"><i class="fa fa-check"></i><b>4.1</b> Visualization for Regression</a></li>
<li class="chapter" data-level="4.2" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#the-lm-function"><i class="fa fa-check"></i><b>4.2</b> The <code>lm()</code> Function</a></li>
<li class="chapter" data-level="4.3" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#hypothesis-testing"><i class="fa fa-check"></i><b>4.3</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="4.4" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#prediction"><i class="fa fa-check"></i><b>4.4</b> Prediction</a></li>
<li class="chapter" data-level="4.5" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#unusual-observations"><i class="fa fa-check"></i><b>4.5</b> Unusual Observations</a></li>
<li class="chapter" data-level="4.6" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#adding-complexity"><i class="fa fa-check"></i><b>4.6</b> Adding Complexity</a><ul>
<li class="chapter" data-level="4.6.1" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#interactions"><i class="fa fa-check"></i><b>4.6.1</b> Interactions</a></li>
<li class="chapter" data-level="4.6.2" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#polynomials"><i class="fa fa-check"></i><b>4.6.2</b> Polynomials</a></li>
<li class="chapter" data-level="4.6.3" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#transformations"><i class="fa fa-check"></i><b>4.6.3</b> Transformations</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#rmarkdown"><i class="fa fa-check"></i><b>4.7</b> <code>rmarkdown</code></a></li>
</ul></li>
<li class="part"><span><b>II Regression</b></span></li>
<li class="chapter" data-level="5" data-path="regression-overview.html"><a href="regression-overview.html"><i class="fa fa-check"></i><b>5</b> Overview</a><ul>
<li class="chapter" data-level="5.1" data-path="regression-overview.html"><a href="regression-overview.html#regression-notation"><i class="fa fa-check"></i><b>5.1</b> Regression Notation</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>6</b> Linear Models</a><ul>
<li class="chapter" data-level="6.1" data-path="linear-models.html"><a href="linear-models.html#assesing-model-accuracy"><i class="fa fa-check"></i><b>6.1</b> Assesing Model Accuracy</a></li>
<li class="chapter" data-level="6.2" data-path="linear-models.html"><a href="linear-models.html#model-complexity"><i class="fa fa-check"></i><b>6.2</b> Model Complexity</a></li>
<li class="chapter" data-level="6.3" data-path="linear-models.html"><a href="linear-models.html#test-train-split"><i class="fa fa-check"></i><b>6.3</b> Test-Train Split</a></li>
<li class="chapter" data-level="6.4" data-path="linear-models.html"><a href="linear-models.html#adding-flexibility-to-linear-models"><i class="fa fa-check"></i><b>6.4</b> Adding Flexibility to Linear Models</a></li>
<li class="chapter" data-level="6.5" data-path="linear-models.html"><a href="linear-models.html#choosing-a-model"><i class="fa fa-check"></i><b>6.5</b> Choosing a Model</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="knn-reg.html"><a href="knn-reg.html"><i class="fa fa-check"></i><b>7</b> <span class="math inline">\(k\)</span>-Nearest Neighbors</a><ul>
<li class="chapter" data-level="7.1" data-path="knn-reg.html"><a href="knn-reg.html#parametric-versus-non-parametric-models"><i class="fa fa-check"></i><b>7.1</b> Parametric versus Non-Parametric Models</a></li>
<li class="chapter" data-level="7.2" data-path="knn-reg.html"><a href="knn-reg.html#local-approaches"><i class="fa fa-check"></i><b>7.2</b> Local Approaches</a><ul>
<li class="chapter" data-level="7.2.1" data-path="knn-reg.html"><a href="knn-reg.html#neighbors"><i class="fa fa-check"></i><b>7.2.1</b> Neighbors</a></li>
<li class="chapter" data-level="7.2.2" data-path="knn-reg.html"><a href="knn-reg.html#neighborhoods"><i class="fa fa-check"></i><b>7.2.2</b> Neighborhoods</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="knn-reg.html"><a href="knn-reg.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>7.3</b> <span class="math inline">\(k\)</span>-Nearest Neighbors</a></li>
<li class="chapter" data-level="7.4" data-path="knn-reg.html"><a href="knn-reg.html#tuning-parameters-versus-model-parameters"><i class="fa fa-check"></i><b>7.4</b> Tuning Parameters versus Model Parameters</a></li>
<li class="chapter" data-level="7.5" data-path="knn-reg.html"><a href="knn-reg.html#knn-in-r"><i class="fa fa-check"></i><b>7.5</b> KNN in <code>R</code></a></li>
<li class="chapter" data-level="7.6" data-path="knn-reg.html"><a href="knn-reg.html#choosing-k"><i class="fa fa-check"></i><b>7.6</b> Choosing <span class="math inline">\(k\)</span></a></li>
<li class="chapter" data-level="7.7" data-path="knn-reg.html"><a href="knn-reg.html#linear-versus-non-linear"><i class="fa fa-check"></i><b>7.7</b> Linear versus Non-Linear</a></li>
<li class="chapter" data-level="7.8" data-path="knn-reg.html"><a href="knn-reg.html#scaling-data"><i class="fa fa-check"></i><b>7.8</b> Scaling Data</a></li>
<li class="chapter" data-level="7.9" data-path="knn-reg.html"><a href="knn-reg.html#curse-of-dimensionality"><i class="fa fa-check"></i><b>7.9</b> Curse of Dimensionality</a></li>
<li class="chapter" data-level="7.10" data-path="knn-reg.html"><a href="knn-reg.html#train-time-versus-test-time"><i class="fa fa-check"></i><b>7.10</b> Train Time versus Test Time</a></li>
<li class="chapter" data-level="7.11" data-path="knn-reg.html"><a href="knn-reg.html#interpretability"><i class="fa fa-check"></i><b>7.11</b> Interpretability</a></li>
<li class="chapter" data-level="7.12" data-path="knn-reg.html"><a href="knn-reg.html#data-example"><i class="fa fa-check"></i><b>7.12</b> Data Example</a></li>
<li class="chapter" data-level="7.13" data-path="knn-reg.html"><a href="knn-reg.html#rmarkdown-1"><i class="fa fa-check"></i><b>7.13</b> <code>rmarkdown</code></a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="biasvariance-tradeoff.html"><a href="biasvariance-tradeoff.html"><i class="fa fa-check"></i><b>8</b> Bias–Variance Tradeoff</a><ul>
<li class="chapter" data-level="8.1" data-path="biasvariance-tradeoff.html"><a href="biasvariance-tradeoff.html#reducible-and-irreducible-error"><i class="fa fa-check"></i><b>8.1</b> Reducible and Irreducible Error</a></li>
<li class="chapter" data-level="8.2" data-path="biasvariance-tradeoff.html"><a href="biasvariance-tradeoff.html#bias-variance-decomposition"><i class="fa fa-check"></i><b>8.2</b> Bias-Variance Decomposition</a></li>
<li class="chapter" data-level="8.3" data-path="biasvariance-tradeoff.html"><a href="biasvariance-tradeoff.html#simulation"><i class="fa fa-check"></i><b>8.3</b> Simulation</a></li>
<li class="chapter" data-level="8.4" data-path="biasvariance-tradeoff.html"><a href="biasvariance-tradeoff.html#estimating-expected-prediction-error"><i class="fa fa-check"></i><b>8.4</b> Estimating Expected Prediction Error</a></li>
<li class="chapter" data-level="8.5" data-path="biasvariance-tradeoff.html"><a href="biasvariance-tradeoff.html#rmarkdown-2"><i class="fa fa-check"></i><b>8.5</b> <code>rmarkdown</code></a></li>
</ul></li>
<li class="part"><span><b>III Classification</b></span></li>
<li class="chapter" data-level="9" data-path="classification-overview.html"><a href="classification-overview.html"><i class="fa fa-check"></i><b>9</b> Overview</a><ul>
<li class="chapter" data-level="9.1" data-path="classification-overview.html"><a href="classification-overview.html#visualization-for-classification"><i class="fa fa-check"></i><b>9.1</b> Visualization for Classification</a></li>
<li class="chapter" data-level="9.2" data-path="classification-overview.html"><a href="classification-overview.html#a-simple-classifier"><i class="fa fa-check"></i><b>9.2</b> A Simple Classifier</a></li>
<li class="chapter" data-level="9.3" data-path="classification-overview.html"><a href="classification-overview.html#metrics-for-classification"><i class="fa fa-check"></i><b>9.3</b> Metrics for Classification</a></li>
<li class="chapter" data-level="9.4" data-path="classification-overview.html"><a href="classification-overview.html#rmarkdown-3"><i class="fa fa-check"></i><b>9.4</b> <code>rmarkdown</code></a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a><ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#linear-regression"><i class="fa fa-check"></i><b>10.1</b> Linear Regression</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#bayes-classifier"><i class="fa fa-check"></i><b>10.2</b> Bayes Classifier</a></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-with-glm"><i class="fa fa-check"></i><b>10.3</b> Logistic Regression with <code>glm()</code></a></li>
<li class="chapter" data-level="10.4" data-path="logistic-regression.html"><a href="logistic-regression.html#roc-curves"><i class="fa fa-check"></i><b>10.4</b> ROC Curves</a></li>
<li class="chapter" data-level="10.5" data-path="logistic-regression.html"><a href="logistic-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>10.5</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="10.6" data-path="logistic-regression.html"><a href="logistic-regression.html#rmarkdown-4"><i class="fa fa-check"></i><b>10.6</b> <code>rmarkdown</code></a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="generative-models.html"><a href="generative-models.html"><i class="fa fa-check"></i><b>11</b> Generative Models</a><ul>
<li class="chapter" data-level="11.1" data-path="generative-models.html"><a href="generative-models.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>11.1</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="11.2" data-path="generative-models.html"><a href="generative-models.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>11.2</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="11.3" data-path="generative-models.html"><a href="generative-models.html#naive-bayes"><i class="fa fa-check"></i><b>11.3</b> Naive Bayes</a></li>
<li class="chapter" data-level="11.4" data-path="generative-models.html"><a href="generative-models.html#discrete-inputs"><i class="fa fa-check"></i><b>11.4</b> Discrete Inputs</a></li>
<li class="chapter" data-level="11.5" data-path="generative-models.html"><a href="generative-models.html#rmarkdown-5"><i class="fa fa-check"></i><b>11.5</b> <code>rmarkdown</code></a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="knn-class.html"><a href="knn-class.html"><i class="fa fa-check"></i><b>12</b> k-Nearest Neighbors</a><ul>
<li class="chapter" data-level="12.1" data-path="knn-class.html"><a href="knn-class.html#binary-data-example"><i class="fa fa-check"></i><b>12.1</b> Binary Data Example</a></li>
<li class="chapter" data-level="12.2" data-path="knn-class.html"><a href="knn-class.html#categorical-data"><i class="fa fa-check"></i><b>12.2</b> Categorical Data</a></li>
<li class="chapter" data-level="12.3" data-path="knn-class.html"><a href="knn-class.html#external-links"><i class="fa fa-check"></i><b>12.3</b> External Links</a></li>
<li class="chapter" data-level="12.4" data-path="knn-class.html"><a href="knn-class.html#rmarkdown-6"><i class="fa fa-check"></i><b>12.4</b> <code>rmarkdown</code></a></li>
</ul></li>
<li class="part"><span><b>IV Unsupervised Learning</b></span></li>
<li class="chapter" data-level="13" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html"><i class="fa fa-check"></i><b>13</b> Overview</a><ul>
<li class="chapter" data-level="13.1" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#methods"><i class="fa fa-check"></i><b>13.1</b> Methods</a><ul>
<li class="chapter" data-level="13.1.1" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#principal-component-analysis"><i class="fa fa-check"></i><b>13.1.1</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="13.1.2" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#k-means-clustering"><i class="fa fa-check"></i><b>13.1.2</b> <span class="math inline">\(k\)</span>-Means Clustering</a></li>
<li class="chapter" data-level="13.1.3" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#hierarchical-clustering"><i class="fa fa-check"></i><b>13.1.3</b> Hierarchical Clustering</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#examples"><i class="fa fa-check"></i><b>13.2</b> Examples</a><ul>
<li class="chapter" data-level="13.2.1" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#us-arrests"><i class="fa fa-check"></i><b>13.2.1</b> US Arrests</a></li>
<li class="chapter" data-level="13.2.2" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#simulated-data"><i class="fa fa-check"></i><b>13.2.2</b> Simulated Data</a></li>
<li class="chapter" data-level="13.2.3" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#iris-data"><i class="fa fa-check"></i><b>13.2.3</b> Iris Data</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#external-links-1"><i class="fa fa-check"></i><b>13.3</b> External Links</a></li>
<li class="chapter" data-level="13.4" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#rmarkdown-7"><i class="fa fa-check"></i><b>13.4</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="principal-component-analysis-1.html"><a href="principal-component-analysis-1.html"><i class="fa fa-check"></i><b>14</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="15" data-path="k-means.html"><a href="k-means.html"><i class="fa fa-check"></i><b>15</b> k-Means</a></li>
<li class="chapter" data-level="16" data-path="mixture-models.html"><a href="mixture-models.html"><i class="fa fa-check"></i><b>16</b> Mixture Models</a></li>
<li class="chapter" data-level="17" data-path="hierarchical-clustering-1.html"><a href="hierarchical-clustering-1.html"><i class="fa fa-check"></i><b>17</b> Hierarchical Clustering</a></li>
<li class="part"><span><b>V In Practice</b></span></li>
<li class="chapter" data-level="18" data-path="practice-overview.html"><a href="practice-overview.html"><i class="fa fa-check"></i><b>18</b> Overview</a></li>
<li class="chapter" data-level="19" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html"><i class="fa fa-check"></i><b>19</b> Supervised Learning Overview</a><ul>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#bayes-classifier-1"><i class="fa fa-check"></i>Bayes Classifier</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#the-bias-variance-tradeoff"><i class="fa fa-check"></i>The Bias-Variance Tradeoff</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#the-test-train-split"><i class="fa fa-check"></i>The Test-Train Split</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#classification-methods"><i class="fa fa-check"></i>Classification Methods</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#discriminative-versus-generative-methods"><i class="fa fa-check"></i>Discriminative versus Generative Methods</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#parametric-and-non-parametric-methods"><i class="fa fa-check"></i>Parametric and Non-Parametric Methods</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#tuning-parameters"><i class="fa fa-check"></i>Tuning Parameters</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#cross-validation"><i class="fa fa-check"></i>Cross-Validation</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#curse-of-dimensionality-1"><i class="fa fa-check"></i>Curse of Dimensionality</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#no-free-lunch-theorem"><i class="fa fa-check"></i>No-Free-Lunch Theorem</a></li>
<li class="chapter" data-level="19.1" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#external-links-2"><i class="fa fa-check"></i><b>19.1</b> External Links</a></li>
<li class="chapter" data-level="19.2" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#rmarkdown-8"><i class="fa fa-check"></i><b>19.2</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="resampling.html"><a href="resampling.html"><i class="fa fa-check"></i><b>20</b> Resampling</a><ul>
<li class="chapter" data-level="20.1" data-path="resampling.html"><a href="resampling.html#validation-set-approach"><i class="fa fa-check"></i><b>20.1</b> Validation-Set Approach</a></li>
<li class="chapter" data-level="20.2" data-path="resampling.html"><a href="resampling.html#cross-validation-1"><i class="fa fa-check"></i><b>20.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="20.3" data-path="resampling.html"><a href="resampling.html#test-data"><i class="fa fa-check"></i><b>20.3</b> Test Data</a></li>
<li class="chapter" data-level="20.4" data-path="resampling.html"><a href="resampling.html#bootstrap"><i class="fa fa-check"></i><b>20.4</b> Bootstrap</a></li>
<li class="chapter" data-level="20.5" data-path="resampling.html"><a href="resampling.html#which-k"><i class="fa fa-check"></i><b>20.5</b> Which <span class="math inline">\(K\)</span>?</a></li>
<li class="chapter" data-level="20.6" data-path="resampling.html"><a href="resampling.html#summary"><i class="fa fa-check"></i><b>20.6</b> Summary</a></li>
<li class="chapter" data-level="20.7" data-path="resampling.html"><a href="resampling.html#external-links-3"><i class="fa fa-check"></i><b>20.7</b> External Links</a></li>
<li class="chapter" data-level="20.8" data-path="resampling.html"><a href="resampling.html#rmarkdown-9"><i class="fa fa-check"></i><b>20.8</b> <code>rmarkdown</code></a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="the-caret-package.html"><a href="the-caret-package.html"><i class="fa fa-check"></i><b>21</b> The <code>caret</code> Package</a><ul>
<li class="chapter" data-level="21.1" data-path="the-caret-package.html"><a href="the-caret-package.html#classification"><i class="fa fa-check"></i><b>21.1</b> Classification</a><ul>
<li class="chapter" data-level="21.1.1" data-path="the-caret-package.html"><a href="the-caret-package.html#tuning"><i class="fa fa-check"></i><b>21.1.1</b> Tuning</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="the-caret-package.html"><a href="the-caret-package.html#regression"><i class="fa fa-check"></i><b>21.2</b> Regression</a><ul>
<li class="chapter" data-level="21.2.1" data-path="the-caret-package.html"><a href="the-caret-package.html#methods-1"><i class="fa fa-check"></i><b>21.2.1</b> Methods</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="the-caret-package.html"><a href="the-caret-package.html#external-links-4"><i class="fa fa-check"></i><b>21.3</b> External Links</a></li>
<li class="chapter" data-level="21.4" data-path="the-caret-package.html"><a href="the-caret-package.html#rmarkdown-10"><i class="fa fa-check"></i><b>21.4</b> <code>rmarkdown</code></a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="subset-selection.html"><a href="subset-selection.html"><i class="fa fa-check"></i><b>22</b> Subset Selection</a><ul>
<li class="chapter" data-level="22.1" data-path="subset-selection.html"><a href="subset-selection.html#aic-bic-and-cp"><i class="fa fa-check"></i><b>22.1</b> AIC, BIC, and Cp</a><ul>
<li class="chapter" data-level="22.1.1" data-path="subset-selection.html"><a href="subset-selection.html#leaps-package"><i class="fa fa-check"></i><b>22.1.1</b> <code>leaps</code> Package</a></li>
<li class="chapter" data-level="22.1.2" data-path="subset-selection.html"><a href="subset-selection.html#best-subset"><i class="fa fa-check"></i><b>22.1.2</b> Best Subset</a></li>
<li class="chapter" data-level="22.1.3" data-path="subset-selection.html"><a href="subset-selection.html#stepwise-methods"><i class="fa fa-check"></i><b>22.1.3</b> Stepwise Methods</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="subset-selection.html"><a href="subset-selection.html#validated-rmse"><i class="fa fa-check"></i><b>22.2</b> Validated RMSE</a></li>
<li class="chapter" data-level="22.3" data-path="subset-selection.html"><a href="subset-selection.html#external-links-5"><i class="fa fa-check"></i><b>22.3</b> External Links</a></li>
<li class="chapter" data-level="22.4" data-path="subset-selection.html"><a href="subset-selection.html#rmarkdown-11"><i class="fa fa-check"></i><b>22.4</b> RMarkdown</a></li>
</ul></li>
<li class="part"><span><b>VI The Modern Era</b></span></li>
<li class="chapter" data-level="23" data-path="modern-overview.html"><a href="modern-overview.html"><i class="fa fa-check"></i><b>23</b> Overview</a></li>
<li class="chapter" data-level="24" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>24</b> Regularization</a><ul>
<li class="chapter" data-level="24.1" data-path="regularization.html"><a href="regularization.html#ridge-regression"><i class="fa fa-check"></i><b>24.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="24.2" data-path="regularization.html"><a href="regularization.html#lasso"><i class="fa fa-check"></i><b>24.2</b> Lasso</a></li>
<li class="chapter" data-level="24.3" data-path="regularization.html"><a href="regularization.html#broom"><i class="fa fa-check"></i><b>24.3</b> <code>broom</code></a></li>
<li class="chapter" data-level="24.4" data-path="regularization.html"><a href="regularization.html#simulated-data-p-n"><i class="fa fa-check"></i><b>24.4</b> Simulated Data, <span class="math inline">\(p &gt; n\)</span></a></li>
<li class="chapter" data-level="24.5" data-path="regularization.html"><a href="regularization.html#external-links-6"><i class="fa fa-check"></i><b>24.5</b> External Links</a></li>
<li class="chapter" data-level="24.6" data-path="regularization.html"><a href="regularization.html#rmarkdown-12"><i class="fa fa-check"></i><b>24.6</b> <code>rmarkdown</code></a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="elastic-net.html"><a href="elastic-net.html"><i class="fa fa-check"></i><b>25</b> Elastic Net</a><ul>
<li class="chapter" data-level="25.1" data-path="elastic-net.html"><a href="elastic-net.html#hitters-data"><i class="fa fa-check"></i><b>25.1</b> Hitters Data</a></li>
<li class="chapter" data-level="25.2" data-path="elastic-net.html"><a href="elastic-net.html#elastic-net-for-regression"><i class="fa fa-check"></i><b>25.2</b> Elastic Net for Regression</a></li>
<li class="chapter" data-level="25.3" data-path="elastic-net.html"><a href="elastic-net.html#elastic-net-for-classification"><i class="fa fa-check"></i><b>25.3</b> Elastic Net for Classification</a></li>
<li class="chapter" data-level="25.4" data-path="elastic-net.html"><a href="elastic-net.html#external-links-7"><i class="fa fa-check"></i><b>25.4</b> External Links</a></li>
<li class="chapter" data-level="25.5" data-path="elastic-net.html"><a href="elastic-net.html#rmarkdown-13"><i class="fa fa-check"></i><b>25.5</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="trees.html"><a href="trees.html"><i class="fa fa-check"></i><b>26</b> Trees</a><ul>
<li class="chapter" data-level="26.1" data-path="trees.html"><a href="trees.html#classification-trees"><i class="fa fa-check"></i><b>26.1</b> Classification Trees</a></li>
<li class="chapter" data-level="26.2" data-path="trees.html"><a href="trees.html#regression-trees"><i class="fa fa-check"></i><b>26.2</b> Regression Trees</a></li>
<li class="chapter" data-level="26.3" data-path="trees.html"><a href="trees.html#rpart-package"><i class="fa fa-check"></i><b>26.3</b> <code>rpart</code> Package</a></li>
<li class="chapter" data-level="26.4" data-path="trees.html"><a href="trees.html#external-links-8"><i class="fa fa-check"></i><b>26.4</b> External Links</a></li>
<li class="chapter" data-level="26.5" data-path="trees.html"><a href="trees.html#rmarkdown-14"><i class="fa fa-check"></i><b>26.5</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="ensemble-methods.html"><a href="ensemble-methods.html"><i class="fa fa-check"></i><b>27</b> Ensemble Methods</a><ul>
<li class="chapter" data-level="27.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#regression-1"><i class="fa fa-check"></i><b>27.1</b> Regression</a><ul>
<li class="chapter" data-level="27.1.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#tree-model"><i class="fa fa-check"></i><b>27.1.1</b> Tree Model</a></li>
<li class="chapter" data-level="27.1.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#linear-model"><i class="fa fa-check"></i><b>27.1.2</b> Linear Model</a></li>
<li class="chapter" data-level="27.1.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#bagging"><i class="fa fa-check"></i><b>27.1.3</b> Bagging</a></li>
<li class="chapter" data-level="27.1.4" data-path="ensemble-methods.html"><a href="ensemble-methods.html#random-forest"><i class="fa fa-check"></i><b>27.1.4</b> Random Forest</a></li>
<li class="chapter" data-level="27.1.5" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting"><i class="fa fa-check"></i><b>27.1.5</b> Boosting</a></li>
<li class="chapter" data-level="27.1.6" data-path="ensemble-methods.html"><a href="ensemble-methods.html#results"><i class="fa fa-check"></i><b>27.1.6</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="27.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#classification-1"><i class="fa fa-check"></i><b>27.2</b> Classification</a><ul>
<li class="chapter" data-level="27.2.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#tree-model-1"><i class="fa fa-check"></i><b>27.2.1</b> Tree Model</a></li>
<li class="chapter" data-level="27.2.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#logistic-regression-1"><i class="fa fa-check"></i><b>27.2.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="27.2.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#bagging-1"><i class="fa fa-check"></i><b>27.2.3</b> Bagging</a></li>
<li class="chapter" data-level="27.2.4" data-path="ensemble-methods.html"><a href="ensemble-methods.html#random-forest-1"><i class="fa fa-check"></i><b>27.2.4</b> Random Forest</a></li>
<li class="chapter" data-level="27.2.5" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting-1"><i class="fa fa-check"></i><b>27.2.5</b> Boosting</a></li>
<li class="chapter" data-level="27.2.6" data-path="ensemble-methods.html"><a href="ensemble-methods.html#results-1"><i class="fa fa-check"></i><b>27.2.6</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#tuning-1"><i class="fa fa-check"></i><b>27.3</b> Tuning</a><ul>
<li class="chapter" data-level="27.3.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#random-forest-and-bagging"><i class="fa fa-check"></i><b>27.3.1</b> Random Forest and Bagging</a></li>
<li class="chapter" data-level="27.3.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting-2"><i class="fa fa-check"></i><b>27.3.2</b> Boosting</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="ensemble-methods.html"><a href="ensemble-methods.html#tree-versus-ensemble-boundaries"><i class="fa fa-check"></i><b>27.4</b> Tree versus Ensemble Boundaries</a></li>
<li class="chapter" data-level="27.5" data-path="ensemble-methods.html"><a href="ensemble-methods.html#external-links-9"><i class="fa fa-check"></i><b>27.5</b> External Links</a></li>
<li class="chapter" data-level="27.6" data-path="ensemble-methods.html"><a href="ensemble-methods.html#rmarkdown-15"><i class="fa fa-check"></i><b>27.6</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="artificial-neural-networks.html"><a href="artificial-neural-networks.html"><i class="fa fa-check"></i><b>28</b> Artificial Neural Networks</a></li>
<li class="part"><span><b>VII Appendix</b></span></li>
<li class="chapter" data-level="29" data-path="appendix-overview.html"><a href="appendix-overview.html"><i class="fa fa-check"></i><b>29</b> Overview</a></li>
<li class="chapter" data-level="30" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>30</b> Non-Linear Models</a></li>
<li class="chapter" data-level="31" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html"><i class="fa fa-check"></i><b>31</b> Regularized Discriminant Analysis</a></li>
<li class="chapter" data-level="32" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>32</b> Support Vector Machines</a></li>
<li class="divider"></li>
<li><a href="https://github.com/daviddalpiaz/r4sl" target="blank">&copy; 2017 David Dalpiaz</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><code>R</code> for Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="knn-reg" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> <span class="math inline">\(k\)</span>-Nearest Neighbors</h1>
<p><strong>Chapter Status:</strong> Under Constructions. Main ideas in place but lack narrative. Functional version of much of the code exist but will be cleaned up. Some code and simulation examples need to be expanded.</p>
<ul>
<li><p>TODO: last chapter..</p></li>
<li>TODO: recall goal
<ul>
<li>frame around estimating regression function</li>
</ul></li>
</ul>
<div id="parametric-versus-non-parametric-models" class="section level2">
<h2><span class="header-section-number">7.1</span> Parametric versus Non-Parametric Models</h2>
<ul>
<li>TODO: How they estimate…</li>
</ul>
<p><span class="math display">\[
f(x) = \mathbb{E}[Y \mid X = x]
\]</span></p>
<ul>
<li>TODO: parametric approaches assume form</li>
</ul>
<p><span class="math display">\[
f(x) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_p x_p
\]</span></p>
<ul>
<li>TODO: non-parametric methods consider locality</li>
</ul>
<p><span class="math display">\[
\hat{f}(x) = \text{average}(\{ y_i : x_i = x \})
\]</span></p>
<ul>
<li>TODO: since often no points will satisfy that requirement</li>
</ul>
<p><span class="math display">\[
\hat{f}(x) = \text{average}( \{ y_i : x_i \text{ equal to (or very close to) x} \} )
\]</span></p>
</div>
<div id="local-approaches" class="section level2">
<h2><span class="header-section-number">7.2</span> Local Approaches</h2>
<ul>
<li>TODO: how do you figure out what is local? what is “close to”?</li>
</ul>
<div id="neighbors" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Neighbors</h3>
<ul>
<li>example: knn</li>
</ul>
</div>
<div id="neighborhoods" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Neighborhoods</h3>
<ul>
<li>example: trees</li>
</ul>
</div>
</div>
<div id="k-nearest-neighbors" class="section level2">
<h2><span class="header-section-number">7.3</span> <span class="math inline">\(k\)</span>-Nearest Neighbors</h2>
<ul>
<li>TODO: for a concrete example of a non-parametric method…</li>
</ul>
<p><span class="math display">\[
\hat{f}_k(x) = \frac{1}{k} \sum_{i \in \mathcal{N}_k(x, \mathcal{D})} y_i
\]</span></p>
<ul>
<li>TODO: how is nearest defined?
<ul>
<li>usually euclidean, but could be any distance</li>
</ul></li>
<li>TODO: implicit minimization (compared to explicit minimization in lm())
<ul>
<li>fitting really just amounts to picking a k, and seeing the training data</li>
</ul></li>
<li>TODO: basic picture
<ul>
<li>for various k’s?</li>
</ul></li>
</ul>
</div>
<div id="tuning-parameters-versus-model-parameters" class="section level2">
<h2><span class="header-section-number">7.4</span> Tuning Parameters versus Model Parameters</h2>
<ul>
<li>tune (hyper) = how to learn from the data, user specified
<ul>
<li>not specific to non-parametric methods</li>
</ul></li>
<li>model = learned from the data, user specifies how many and form</li>
</ul>
</div>
<div id="knn-in-r" class="section level2">
<h2><span class="header-section-number">7.5</span> KNN in <code>R</code></h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(FNN)
<span class="kw">library</span>(MASS)
<span class="kw">data</span>(Boston)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">42</span>)
boston_idx =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(Boston), <span class="dt">size =</span> <span class="dv">250</span>)
trn_boston =<span class="st"> </span>Boston[boston_idx, ]
tst_boston  =<span class="st"> </span>Boston[-boston_idx, ]</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X_trn_boston =<span class="st"> </span>trn_boston[<span class="st">&quot;lstat&quot;</span>]
X_tst_boston =<span class="st"> </span>tst_boston[<span class="st">&quot;lstat&quot;</span>]
y_trn_boston =<span class="st"> </span>trn_boston[<span class="st">&quot;medv&quot;</span>]
y_tst_boston =<span class="st"> </span>tst_boston[<span class="st">&quot;medv&quot;</span>]</code></pre></div>
<p>We create an additional “test” set <code>lstat_grid</code>, that is a grid of <code>lstat</code> values at which we will predict <code>medv</code> in order to create graphics.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X_trn_boston_min =<span class="st"> </span><span class="kw">min</span>(X_trn_boston)
X_trn_boston_max =<span class="st"> </span><span class="kw">max</span>(X_trn_boston)
lstat_grid =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">lstat =</span> <span class="kw">seq</span>(X_trn_boston_min, X_trn_boston_max, 
                                    <span class="dt">by =</span> <span class="fl">0.01</span>))</code></pre></div>
<p>To perform KNN for regression, we will need <code>knn.reg()</code> from the <code>FNN</code> package. Notice that, we do <strong>not</strong> load this package, but instead use <code>FNN::knn.reg</code> to access the function. Note that, in the future, we’ll need to be careful about loading the <code>FNN</code> package as it also contains a function called <code>knn</code>. This function also appears in the <code>class</code> package which we will likely use later.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">knn.reg</span>(<span class="dt">train =</span> ?, <span class="dt">test =</span> ?, <span class="dt">y =</span> ?, <span class="dt">k =</span> ?)</code></pre></div>
<p>INPUT</p>
<ul>
<li><code>train</code>: the predictors of the training data</li>
<li><code>test</code>: the predictor values, <span class="math inline">\(x\)</span>, at which we would like to make predictions</li>
<li><code>y</code>: the response for the training data</li>
<li><code>k</code>: the number of neighbors to consider</li>
</ul>
<p>OUTPUT</p>
<ul>
<li>the output of <code>knn.reg()</code> is exactly <span class="math inline">\(\hat{f}_k(x)\)</span></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_001 =<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> X_trn_boston, <span class="dt">test =</span> lstat_grid, <span class="dt">y =</span> y_trn_boston, <span class="dt">k =</span> <span class="dv">1</span>)
pred_005 =<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> X_trn_boston, <span class="dt">test =</span> lstat_grid, <span class="dt">y =</span> y_trn_boston, <span class="dt">k =</span> <span class="dv">5</span>)
pred_010 =<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> X_trn_boston, <span class="dt">test =</span> lstat_grid, <span class="dt">y =</span> y_trn_boston, <span class="dt">k =</span> <span class="dv">10</span>)
pred_050 =<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> X_trn_boston, <span class="dt">test =</span> lstat_grid, <span class="dt">y =</span> y_trn_boston, <span class="dt">k =</span> <span class="dv">50</span>)
pred_100 =<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> X_trn_boston, <span class="dt">test =</span> lstat_grid, <span class="dt">y =</span> y_trn_boston, <span class="dt">k =</span> <span class="dv">100</span>)
pred_250 =<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> X_trn_boston, <span class="dt">test =</span> lstat_grid, <span class="dt">y =</span> y_trn_boston, <span class="dt">k =</span> <span class="dv">250</span>)</code></pre></div>
<p>We make predictions for a large number of possible values of <code>lstat</code>, for different values of <code>k</code>. Note that <code>250</code> is the total number of observations in this training dataset.</p>
<p><img src="07-knn-reg_files/figure-html/unnamed-chunk-7-1.png" width="576" /></p>
<ul>
<li>TODO: Orange “curves” are <span class="math inline">\(\hat{f}_k(x)\)</span> where <span class="math inline">\(x\)</span> are the values we defined in <code>lstat_grid</code>. So really a bunch of predictions with interpolated lines, but you can’t really tell…</li>
</ul>
<p>We see that <code>k = 1</code> is clearly overfitting, as <code>k = 1</code> is a very complex, highly variable model. Conversely, <code>k = 250</code> is clearly underfitting the data, as <code>k = 250</code> is a very simple, low variance model. In fact, here it is predicting a simple average of all the data at each point.</p>
</div>
<div id="choosing-k" class="section level2">
<h2><span class="header-section-number">7.6</span> Choosing <span class="math inline">\(k\)</span></h2>
<ul>
<li>low <code>k</code> = very complex model. very wiggly. specifically jagged</li>
<li><p>high <code>k</code> = very inflexible model. very smooth.</p></li>
<li>want: something in the middle which predicts well on unseen data</li>
<li><p>that is, want <span class="math inline">\(\hat{f}_k\)</span> to minimize</p></li>
</ul>
<p><span class="math display">\[
\text{EPE}\left(Y, \hat{f}_k(X)\right) = 
\mathbb{E}_{X, Y, \mathcal{D}} \left[  (Y - \hat{f}_k(X))^2 \right]
\]</span></p>
<ul>
<li>TODO: Test MSE is an estimate of this. So finding best test RMSE will be our strategy. (Best test RMSE is same as best MSE, but with more understandable units.)</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rmse =<span class="st"> </span>function(actual, predicted) {
  <span class="kw">sqrt</span>(<span class="kw">mean</span>((actual -<span class="st"> </span>predicted) ^<span class="st"> </span><span class="dv">2</span>))
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define helper function for getting knn.reg predictions</span>
<span class="co"># note: this function is highly specific to this situation and dataset</span>
make_knn_pred =<span class="st"> </span>function(<span class="dt">k =</span> <span class="dv">1</span>, training, predicting) {
  pred =<span class="st"> </span>FNN::<span class="kw">knn.reg</span>(<span class="dt">train =</span> training[<span class="st">&quot;lstat&quot;</span>], 
                      <span class="dt">test =</span> predicting[<span class="st">&quot;lstat&quot;</span>], 
                      <span class="dt">y =</span> training$medv, <span class="dt">k =</span> k)$pred
  act  =<span class="st"> </span>predicting$medv
  <span class="kw">rmse</span>(<span class="dt">predicted =</span> pred, <span class="dt">actual =</span> act)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define values of k to evaluate</span>
k =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">250</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># get requested train RMSEs</span>
knn_trn_rmse =<span class="st"> </span><span class="kw">sapply</span>(k, make_knn_pred, 
                      <span class="dt">training =</span> trn_boston, 
                      <span class="dt">predicting =</span> trn_boston)
<span class="co"># get requested test RMSEs</span>
knn_tst_rmse =<span class="st"> </span><span class="kw">sapply</span>(k, make_knn_pred, 
                      <span class="dt">training =</span> trn_boston, 
                      <span class="dt">predicting =</span> tst_boston)

<span class="co"># determine &quot;best&quot; k</span>
best_k =<span class="st"> </span>k[<span class="kw">which.min</span>(knn_tst_rmse)]

<span class="co"># find overfitting, underfitting, and &quot;best&quot;&quot; k</span>
fit_status =<span class="st"> </span><span class="kw">ifelse</span>(k &lt;<span class="st"> </span>best_k, <span class="st">&quot;Over&quot;</span>, <span class="kw">ifelse</span>(k ==<span class="st"> </span>best_k, <span class="st">&quot;Best&quot;</span>, <span class="st">&quot;Under&quot;</span>))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># summarize results</span>
knn_results =<span class="st"> </span><span class="kw">data.frame</span>(
  k,
  <span class="kw">round</span>(knn_trn_rmse, <span class="dv">2</span>),
  <span class="kw">round</span>(knn_tst_rmse, <span class="dv">2</span>),
  fit_status
)
<span class="kw">colnames</span>(knn_results) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;k&quot;</span>, <span class="st">&quot;Train RMSE&quot;</span>, <span class="st">&quot;Test RMSE&quot;</span>, <span class="st">&quot;Fit?&quot;</span>)

<span class="co"># display results</span>
knitr::<span class="kw">kable</span>(knn_results, <span class="dt">escape =</span> <span class="ot">FALSE</span>, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">k</th>
<th align="right">Train RMSE</th>
<th align="right">Test RMSE</th>
<th align="left">Fit?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">2.22</td>
<td align="right">7.50</td>
<td align="left">Over</td>
</tr>
<tr class="even">
<td align="right">5</td>
<td align="right">4.30</td>
<td align="right">5.89</td>
<td align="left">Over</td>
</tr>
<tr class="odd">
<td align="right">10</td>
<td align="right">4.60</td>
<td align="right">5.72</td>
<td align="left">Over</td>
</tr>
<tr class="even">
<td align="right">25</td>
<td align="right">4.66</td>
<td align="right">5.71</td>
<td align="left">Best</td>
</tr>
<tr class="odd">
<td align="right">50</td>
<td align="right">4.99</td>
<td align="right">6.03</td>
<td align="left">Under</td>
</tr>
<tr class="even">
<td align="right">250</td>
<td align="right">8.90</td>
<td align="right">9.47</td>
<td align="left">Under</td>
</tr>
</tbody>
</table>
<ul>
<li>TODO: What about ties? why isn’t k = 1 give 0 training error? There are some non-unique <span class="math inline">\(x_i\)</span> values in the training data. How do we predict when this is the case?</li>
</ul>
</div>
<div id="linear-versus-non-linear" class="section level2">
<h2><span class="header-section-number">7.7</span> Linear versus Non-Linear</h2>
<ul>
<li>TODO; linear relationship example
<ul>
<li>lm() works well</li>
<li>knn “automatically” approximates</li>
</ul></li>
<li>TODO: very non-linear example
<ul>
<li>lm() fails badly
<ul>
<li>could work if …</li>
</ul></li>
<li>knn “automatically” approximates</li>
</ul></li>
</ul>
<p><img src="07-knn-reg_files/figure-html/unnamed-chunk-13-1.png" width="960" /></p>
</div>
<div id="scaling-data" class="section level2">
<h2><span class="header-section-number">7.8</span> Scaling Data</h2>
<ul>
<li>TODO: Sometimes “scale” differentiates between center and scale. <code>R</code> function <code>scale()</code> does both by default. Outputs variables with mean = 0, var = 1.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim_knn_data =<span class="st"> </span>function(<span class="dt">n_obs =</span> <span class="dv">50</span>) {
  x1 =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">length.out =</span> n_obs)
  x2 =<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> n_obs, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">2</span>)
  x3 =<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> n_obs, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">1</span>)
  x4 =<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> n_obs, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">5</span>)
  x5 =<span class="st"> </span><span class="kw">runif</span>(<span class="dt">n =</span> n_obs, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">5</span>)
  y =<span class="st"> </span>x1 ^<span class="st"> </span><span class="dv">2</span> +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> n_obs)
  <span class="kw">data.frame</span>(y, x1, x2, x3,x4, x5)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">42</span>)
knn_data =<span class="st"> </span><span class="kw">sim_knn_data</span>()</code></pre></div>
<p><img src="07-knn-reg_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<ul>
<li><p>TODO: How should we scale the test data?</p></li>
<li><p>TODO: Show that linear regression is invariant to scaling. KNN is not. - y = b0 + b1x1 + b2x2 + e - y = b0 + b1x1_ + b2x2_ + e - how are these coefficients related - define how the scaling - RMSE for both, RMSE for both ways KNN</p></li>
</ul>
</div>
<div id="curse-of-dimensionality" class="section level2">
<h2><span class="header-section-number">7.9</span> Curse of Dimensionality</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">42</span>)
knn_data_trn =<span class="st"> </span><span class="kw">sim_knn_data</span>()
knn_data_tst =<span class="st"> </span><span class="kw">sim_knn_data</span>()</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define helper function for getting knn.reg predictions</span>
<span class="co"># note: this function is highly specific to this situation and dataset</span>
make_knn_pred =<span class="st"> </span>function(<span class="dt">k =</span> <span class="dv">1</span>, X_trn, X_pred, y_trn, y_pred) {
  pred =<span class="st"> </span>FNN::<span class="kw">knn.reg</span>(<span class="dt">train =</span> <span class="kw">scale</span>(X_trn), <span class="dt">test =</span> <span class="kw">scale</span>(X_pred), <span class="dt">y =</span> y_trn, <span class="dt">k =</span> k)$pred
  act  =<span class="st"> </span>y_pred
  <span class="kw">rmse</span>(<span class="dt">predicted =</span> pred, <span class="dt">actual =</span> act)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># TODO: DRY</span>
cod_train_rmse =<span class="st"> </span><span class="kw">c</span>(
  <span class="kw">make_knn_pred</span> (<span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">X_trn =</span> knn_data_trn[<span class="st">&quot;x1&quot;</span>],  <span class="dt">X_pred =</span> knn_data_trn[<span class="st">&quot;x1&quot;</span>],  
                 <span class="dt">y_trn =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>], <span class="dt">y_pred =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>]),
  <span class="kw">make_knn_pred</span> (<span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">X_trn =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">3</span>], <span class="dt">X_pred =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">3</span>], 
                 <span class="dt">y_trn =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>], <span class="dt">y_pred =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>]),
  <span class="kw">make_knn_pred</span> (<span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">X_trn =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">4</span>], <span class="dt">X_pred =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">4</span>], 
                 <span class="dt">y_trn =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>], <span class="dt">y_pred =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>]),
  <span class="kw">make_knn_pred</span> (<span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">X_trn =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">5</span>], <span class="dt">X_pred =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">5</span>], 
                 <span class="dt">y_trn =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>], <span class="dt">y_pred =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>]),
  <span class="kw">make_knn_pred</span> (<span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">X_trn =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">6</span>], <span class="dt">X_pred =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">6</span>], 
                 <span class="dt">y_trn =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>], <span class="dt">y_pred =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>]))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># TODO: DRY</span>
cod_test_rmse =<span class="st"> </span><span class="kw">c</span>(
  <span class="kw">make_knn_pred</span> (<span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">X_trn =</span> knn_data_trn[<span class="st">&quot;x1&quot;</span>],  <span class="dt">X_pred =</span> knn_data_tst[<span class="st">&quot;x1&quot;</span>],  
                 <span class="dt">y_trn =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>], <span class="dt">y_pred =</span> knn_data_tst[<span class="st">&quot;y&quot;</span>]),
  <span class="kw">make_knn_pred</span> (<span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">X_trn =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">3</span>], <span class="dt">X_pred =</span> knn_data_tst[, <span class="dv">2</span>:<span class="dv">3</span>], 
                 <span class="dt">y_trn =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>], <span class="dt">y_pred =</span> knn_data_tst[<span class="st">&quot;y&quot;</span>]),
  <span class="kw">make_knn_pred</span> (<span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">X_trn =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">4</span>], <span class="dt">X_pred =</span> knn_data_tst[, <span class="dv">2</span>:<span class="dv">4</span>], 
                 <span class="dt">y_trn =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>], <span class="dt">y_pred =</span> knn_data_tst[<span class="st">&quot;y&quot;</span>]),
  <span class="kw">make_knn_pred</span> (<span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">X_trn =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">5</span>], <span class="dt">X_pred =</span> knn_data_tst[, <span class="dv">2</span>:<span class="dv">5</span>], 
                 <span class="dt">y_trn =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>], <span class="dt">y_pred =</span> knn_data_tst[<span class="st">&quot;y&quot;</span>]),
  <span class="kw">make_knn_pred</span> (<span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">X_trn =</span> knn_data_trn[, <span class="dv">2</span>:<span class="dv">6</span>], <span class="dt">X_pred =</span> knn_data_tst[, <span class="dv">2</span>:<span class="dv">6</span>], 
                 <span class="dt">y_trn =</span> knn_data_trn[<span class="st">&quot;y&quot;</span>], <span class="dt">y_pred =</span> knn_data_tst[<span class="st">&quot;y&quot;</span>]))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cod_results =<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">dimension =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>),
  cod_train_rmse,
  cod_test_rmse
)

<span class="kw">colnames</span>(cod_results) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;$p$, Dimension&quot;</span>, <span class="st">&quot;Train RMSE&quot;</span>, <span class="st">&quot;Test RMSE&quot;</span>)

knitr::<span class="kw">kable</span>(cod_results, <span class="dt">escape =</span> <span class="ot">FALSE</span>, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(p\)</span>, Dimension</th>
<th align="right">Train RMSE</th>
<th align="right">Test RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">1.413569</td>
<td align="right">1.565495</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">5.407340</td>
<td align="right">7.212414</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">8.726803</td>
<td align="right">10.629993</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">10.310148</td>
<td align="right">12.933572</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">12.101930</td>
<td align="right">14.256241</td>
</tr>
</tbody>
</table>
<ul>
<li>TODO: Local becomes less local.</li>
</ul>
</div>
<div id="train-time-versus-test-time" class="section level2">
<h2><span class="header-section-number">7.10</span> Train Time versus Test Time</h2>
<ul>
<li>TODO: lm vs knn
<ul>
<li>lm: “slow” train, “fast” test</li>
<li>knn: “fast” train, “slow” test</li>
<li>illustrate with system timings</li>
</ul></li>
</ul>
</div>
<div id="interpretability" class="section level2">
<h2><span class="header-section-number">7.11</span> Interpretability</h2>
<ul>
<li>TODO: lm (high) vs knn (low)
<ul>
<li>somewhat generalizes to parametric vs non-parametric</li>
</ul></li>
</ul>
</div>
<div id="data-example" class="section level2">
<h2><span class="header-section-number">7.12</span> Data Example</h2>
<p>Returning to the <code>Boston</code> dataset, we now use all of the available predictors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X_trn_boston =<span class="st"> </span>trn_boston[, !<span class="kw">names</span>(trn_boston) %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;medv&quot;</span>)]
X_tst_boston =<span class="st"> </span>tst_boston[, !<span class="kw">names</span>(tst_boston) %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;medv&quot;</span>)]
y_trn_boston =<span class="st"> </span>trn_boston[<span class="st">&quot;medv&quot;</span>]
y_tst_boston =<span class="st"> </span>tst_boston[<span class="st">&quot;medv&quot;</span>]</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">scaled_pred =<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> <span class="kw">scale</span>(X_trn_boston), <span class="dt">test =</span> <span class="kw">scale</span>(X_tst_boston), 
                      <span class="dt">y =</span> y_trn_boston, <span class="dt">k =</span> <span class="dv">10</span>)$pred
unscaled_pred =<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> X_trn_boston, <span class="dt">test =</span> X_tst_boston, 
                        <span class="dt">y =</span> y_trn_boston, <span class="dt">k =</span> <span class="dv">10</span>)$pred

<span class="co"># test rmse</span>
<span class="kw">rmse</span>(<span class="dt">predicted =</span> scaled_pred, <span class="dt">actual =</span> y_tst_boston) <span class="co"># with scaling</span></code></pre></div>
<pre><code>## [1] 5.709402</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rmse</span>(<span class="dt">predicted =</span> unscaled_pred, <span class="dt">actual =</span> y_tst_boston) <span class="co"># without scaling</span></code></pre></div>
<pre><code>## [1] 7.540342</code></pre>
<p>Here we see that scaling makes a pretty big difference.</p>
<p>Can you improve this model? Can you find a better <span class="math inline">\(k\)</span>? Can you find a better model by only using some of the predictors?</p>
</div>
<div id="rmarkdown-1" class="section level2">
<h2><span class="header-section-number">7.13</span> <code>rmarkdown</code></h2>
<p>The <code>rmarkdown</code> file for this chapter can be found <a href="07-knn-reg.Rmd"><strong>here</strong></a>. The file was created using <code>R</code> version 3.4.2. The following packages (and their dependencies) were loaded when knitting this file:</p>
<pre><code>## [1] &quot;MASS&quot; &quot;FNN&quot;</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="biasvariance-tradeoff.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/daviddalpiaz/r4sl/edit/master/07-knn-reg.Rmd",
"text": "Edit"
},
"download": "r4sl.pdf",
"toc": {
"collapse": "chapter"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
