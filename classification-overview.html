<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>R for Statistical Learning</title>
  <meta name="description" content="<code>R</code> for Statistical Learning">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="R for Statistical Learning" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://daviddalpiaz.github.io/r4sl/" />
  
  
  <meta name="github-repo" content="daviddalpiaz/r4sl" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="R for Statistical Learning" />
  
  
  

<meta name="author" content="David Dalpiaz">


<meta name="date" content="2017-09-05">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
<link rel="prev" href="simulating-the-biasvariance-tradeoff.html">
<link rel="next" href="logistic-regression.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R for Statistical Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i><b>0.1</b> About This Book</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#organization"><i class="fa fa-check"></i><b>0.2</b> Organization</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#who"><i class="fa fa-check"></i><b>0.3</b> Who?</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#caveat-emptor"><i class="fa fa-check"></i><b>0.4</b> Caveat Emptor</a></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#conventions"><i class="fa fa-check"></i><b>0.5</b> Conventions</a></li>
<li class="chapter" data-level="0.6" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>0.6</b> Acknowledgements</a></li>
<li class="chapter" data-level="0.7" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>0.7</b> License</a></li>
</ul></li>
<li class="part"><span><b>I Prerequisites</b></span></li>
<li class="chapter" data-level="1" data-path="prerequisites-overview.html"><a href="prerequisites-overview.html"><i class="fa fa-check"></i><b>1</b> Overview</a></li>
<li class="chapter" data-level="2" data-path="probability-review.html"><a href="probability-review.html"><i class="fa fa-check"></i><b>2</b> Probability Review</a><ul>
<li class="chapter" data-level="2.1" data-path="probability-review.html"><a href="probability-review.html#probability-models"><i class="fa fa-check"></i><b>2.1</b> Probability Models</a></li>
<li class="chapter" data-level="2.2" data-path="probability-review.html"><a href="probability-review.html#probability-axioms"><i class="fa fa-check"></i><b>2.2</b> Probability Axioms</a></li>
<li class="chapter" data-level="2.3" data-path="probability-review.html"><a href="probability-review.html#probability-rules"><i class="fa fa-check"></i><b>2.3</b> Probability Rules</a></li>
<li class="chapter" data-level="2.4" data-path="probability-review.html"><a href="probability-review.html#random-variables"><i class="fa fa-check"></i><b>2.4</b> Random Variables</a><ul>
<li class="chapter" data-level="2.4.1" data-path="probability-review.html"><a href="probability-review.html#distributions"><i class="fa fa-check"></i><b>2.4.1</b> Distributions</a></li>
<li class="chapter" data-level="2.4.2" data-path="probability-review.html"><a href="probability-review.html#discrete-random-variables"><i class="fa fa-check"></i><b>2.4.2</b> Discrete Random Variables</a></li>
<li class="chapter" data-level="2.4.3" data-path="probability-review.html"><a href="probability-review.html#continuous-random-variables"><i class="fa fa-check"></i><b>2.4.3</b> Continuous Random Variables</a></li>
<li class="chapter" data-level="2.4.4" data-path="probability-review.html"><a href="probability-review.html#several-random-variables"><i class="fa fa-check"></i><b>2.4.4</b> Several Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="probability-review.html"><a href="probability-review.html#expectations"><i class="fa fa-check"></i><b>2.5</b> Expectations</a></li>
<li class="chapter" data-level="2.6" data-path="probability-review.html"><a href="probability-review.html#likelihood"><i class="fa fa-check"></i><b>2.6</b> Likelihood</a></li>
<li class="chapter" data-level="2.7" data-path="probability-review.html"><a href="probability-review.html#videos"><i class="fa fa-check"></i><b>2.7</b> Videos</a></li>
<li class="chapter" data-level="2.8" data-path="probability-review.html"><a href="probability-review.html#references"><i class="fa fa-check"></i><b>2.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="r-rstudio-rmarkdown.html"><a href="r-rstudio-rmarkdown.html"><i class="fa fa-check"></i><b>3</b> <code>R</code>, RStudio, RMarkdown</a><ul>
<li class="chapter" data-level="3.1" data-path="r-rstudio-rmarkdown.html"><a href="r-rstudio-rmarkdown.html#videos-1"><i class="fa fa-check"></i><b>3.1</b> Videos</a></li>
<li class="chapter" data-level="3.2" data-path="r-rstudio-rmarkdown.html"><a href="r-rstudio-rmarkdown.html#template"><i class="fa fa-check"></i><b>3.2</b> Template</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html"><i class="fa fa-check"></i><b>4</b> Modeling Basics in <code>R</code></a><ul>
<li class="chapter" data-level="4.1" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#visualization-for-regression"><i class="fa fa-check"></i><b>4.1</b> Visualization for Regression</a></li>
<li class="chapter" data-level="4.2" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#the-lm-function"><i class="fa fa-check"></i><b>4.2</b> The <code>lm()</code> Function</a></li>
<li class="chapter" data-level="4.3" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#hypothesis-testing"><i class="fa fa-check"></i><b>4.3</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="4.4" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#prediction"><i class="fa fa-check"></i><b>4.4</b> Prediction</a></li>
<li class="chapter" data-level="4.5" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#unusual-observations"><i class="fa fa-check"></i><b>4.5</b> Unusual Observations</a></li>
<li class="chapter" data-level="4.6" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#adding-complexity"><i class="fa fa-check"></i><b>4.6</b> Adding Complexity</a><ul>
<li class="chapter" data-level="4.6.1" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#interactions"><i class="fa fa-check"></i><b>4.6.1</b> Interactions</a></li>
<li class="chapter" data-level="4.6.2" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#polynomials"><i class="fa fa-check"></i><b>4.6.2</b> Polynomials</a></li>
<li class="chapter" data-level="4.6.3" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#transformations"><i class="fa fa-check"></i><b>4.6.3</b> Transformations</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="modeling-basics-in-r.html"><a href="modeling-basics-in-r.html#rmarkdown"><i class="fa fa-check"></i><b>4.7</b> <code>rmarkdown</code></a></li>
</ul></li>
<li class="part"><span><b>II Regression</b></span></li>
<li class="chapter" data-level="5" data-path="regression-overview.html"><a href="regression-overview.html"><i class="fa fa-check"></i><b>5</b> Overview</a><ul>
<li class="chapter" data-level="5.1" data-path="regression-overview.html"><a href="regression-overview.html#assesing-model-accuracy"><i class="fa fa-check"></i><b>5.1</b> Assesing Model Accuracy</a></li>
<li class="chapter" data-level="5.2" data-path="regression-overview.html"><a href="regression-overview.html#model-complexity"><i class="fa fa-check"></i><b>5.2</b> Model Complexity</a></li>
<li class="chapter" data-level="5.3" data-path="regression-overview.html"><a href="regression-overview.html#test-train-split"><i class="fa fa-check"></i><b>5.3</b> Test-Train Split</a></li>
<li class="chapter" data-level="5.4" data-path="regression-overview.html"><a href="regression-overview.html#adding-flexibility-to-linear-models"><i class="fa fa-check"></i><b>5.4</b> Adding Flexibility to Linear Models</a></li>
<li class="chapter" data-level="5.5" data-path="regression-overview.html"><a href="regression-overview.html#choosing-a-model"><i class="fa fa-check"></i><b>5.5</b> Choosing a Model</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>6</b> Linear Models</a></li>
<li class="chapter" data-level="7" data-path="knn-reg.html"><a href="knn-reg.html"><i class="fa fa-check"></i><b>7</b> k-Nearest Neighbors</a></li>
<li class="chapter" data-level="8" data-path="simulating-the-biasvariance-tradeoff.html"><a href="simulating-the-biasvariance-tradeoff.html"><i class="fa fa-check"></i><b>8</b> Simulating the Biasâ€“Variance Tradeoff</a><ul>
<li class="chapter" data-level="8.1" data-path="simulating-the-biasvariance-tradeoff.html"><a href="simulating-the-biasvariance-tradeoff.html#bias-variance-decomposition"><i class="fa fa-check"></i><b>8.1</b> Bias-Variance Decomposition</a></li>
<li class="chapter" data-level="8.2" data-path="simulating-the-biasvariance-tradeoff.html"><a href="simulating-the-biasvariance-tradeoff.html#simulation"><i class="fa fa-check"></i><b>8.2</b> Simulation</a></li>
<li class="chapter" data-level="8.3" data-path="simulating-the-biasvariance-tradeoff.html"><a href="simulating-the-biasvariance-tradeoff.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>8.3</b> Bias-Variance Tradeoff</a></li>
</ul></li>
<li class="part"><span><b>III Classification</b></span></li>
<li class="chapter" data-level="9" data-path="classification-overview.html"><a href="classification-overview.html"><i class="fa fa-check"></i><b>9</b> Overview</a><ul>
<li class="chapter" data-level="9.1" data-path="classification-overview.html"><a href="classification-overview.html#visualization-for-classification"><i class="fa fa-check"></i><b>9.1</b> Visualization for Classification</a></li>
<li class="chapter" data-level="9.2" data-path="classification-overview.html"><a href="classification-overview.html#a-simple-classifier"><i class="fa fa-check"></i><b>9.2</b> A Simple Classifier</a></li>
<li class="chapter" data-level="9.3" data-path="classification-overview.html"><a href="classification-overview.html#metrics-for-classification"><i class="fa fa-check"></i><b>9.3</b> Metrics for Classification</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a><ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#linear-regression"><i class="fa fa-check"></i><b>10.1</b> Linear Regression</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#bayes-classifier"><i class="fa fa-check"></i><b>10.2</b> Bayes Classifier</a></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-with-glm"><i class="fa fa-check"></i><b>10.3</b> Logistic Regression with <code>glm()</code></a></li>
<li class="chapter" data-level="10.4" data-path="logistic-regression.html"><a href="logistic-regression.html#roc-curves"><i class="fa fa-check"></i><b>10.4</b> ROC Curves</a></li>
<li class="chapter" data-level="10.5" data-path="logistic-regression.html"><a href="logistic-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>10.5</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="generative-models.html"><a href="generative-models.html"><i class="fa fa-check"></i><b>11</b> Generative Models</a><ul>
<li class="chapter" data-level="11.1" data-path="generative-models.html"><a href="generative-models.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>11.1</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="11.2" data-path="generative-models.html"><a href="generative-models.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>11.2</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="11.3" data-path="generative-models.html"><a href="generative-models.html#naive-bayes"><i class="fa fa-check"></i><b>11.3</b> Naive Bayes</a></li>
<li class="chapter" data-level="11.4" data-path="generative-models.html"><a href="generative-models.html#discrete-inputs"><i class="fa fa-check"></i><b>11.4</b> Discrete Inputs</a></li>
<li class="chapter" data-level="11.5" data-path="generative-models.html"><a href="generative-models.html#rmarkdown-1"><i class="fa fa-check"></i><b>11.5</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="knn-class.html"><a href="knn-class.html"><i class="fa fa-check"></i><b>12</b> k-Nearest Neighbors</a><ul>
<li class="chapter" data-level="12.1" data-path="knn-class.html"><a href="knn-class.html#classification"><i class="fa fa-check"></i><b>12.1</b> Classification</a><ul>
<li class="chapter" data-level="12.1.1" data-path="knn-class.html"><a href="knn-class.html#default-data"><i class="fa fa-check"></i><b>12.1.1</b> Default Data</a></li>
<li class="chapter" data-level="12.1.2" data-path="knn-class.html"><a href="knn-class.html#iris-data"><i class="fa fa-check"></i><b>12.1.2</b> Iris Data</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="knn-class.html"><a href="knn-class.html#regression"><i class="fa fa-check"></i><b>12.2</b> Regression</a></li>
<li class="chapter" data-level="12.3" data-path="knn-class.html"><a href="knn-class.html#external-links"><i class="fa fa-check"></i><b>12.3</b> External Links</a></li>
<li class="chapter" data-level="12.4" data-path="knn-class.html"><a href="knn-class.html#rmarkdown-2"><i class="fa fa-check"></i><b>12.4</b> RMarkdown</a></li>
</ul></li>
<li class="part"><span><b>IV Unsupervised Learning</b></span></li>
<li class="chapter" data-level="13" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html"><i class="fa fa-check"></i><b>13</b> Overview</a><ul>
<li class="chapter" data-level="13.1" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#methods"><i class="fa fa-check"></i><b>13.1</b> Methods</a><ul>
<li class="chapter" data-level="13.1.1" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#principal-component-analysis"><i class="fa fa-check"></i><b>13.1.1</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="13.1.2" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#k-means-clustering"><i class="fa fa-check"></i><b>13.1.2</b> <span class="math inline">\(k\)</span>-Means Clustering</a></li>
<li class="chapter" data-level="13.1.3" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#hierarchical-clustering"><i class="fa fa-check"></i><b>13.1.3</b> Hierarchical Clustering</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#examples"><i class="fa fa-check"></i><b>13.2</b> Examples</a><ul>
<li class="chapter" data-level="13.2.1" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#us-arrests"><i class="fa fa-check"></i><b>13.2.1</b> US Arrests</a></li>
<li class="chapter" data-level="13.2.2" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#simulated-data"><i class="fa fa-check"></i><b>13.2.2</b> Simulated Data</a></li>
<li class="chapter" data-level="13.2.3" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#iris-data-1"><i class="fa fa-check"></i><b>13.2.3</b> Iris Data</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#external-links-1"><i class="fa fa-check"></i><b>13.3</b> External Links</a></li>
<li class="chapter" data-level="13.4" data-path="unsupervised-overview.html"><a href="unsupervised-overview.html#rmarkdown-3"><i class="fa fa-check"></i><b>13.4</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="principal-component-analysis-1.html"><a href="principal-component-analysis-1.html"><i class="fa fa-check"></i><b>14</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="15" data-path="k-means.html"><a href="k-means.html"><i class="fa fa-check"></i><b>15</b> k-Means</a></li>
<li class="chapter" data-level="16" data-path="mixture-models.html"><a href="mixture-models.html"><i class="fa fa-check"></i><b>16</b> Mixture Models</a></li>
<li class="chapter" data-level="17" data-path="hierarchical-clustering-1.html"><a href="hierarchical-clustering-1.html"><i class="fa fa-check"></i><b>17</b> Hierarchical Clustering</a></li>
<li class="part"><span><b>V In Practice</b></span></li>
<li class="chapter" data-level="18" data-path="practice-overview.html"><a href="practice-overview.html"><i class="fa fa-check"></i><b>18</b> Overview</a></li>
<li class="chapter" data-level="19" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html"><i class="fa fa-check"></i><b>19</b> Supervised Learning Overview</a><ul>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#bayes-classifier-1"><i class="fa fa-check"></i>Bayes Classifier</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#the-bias-variance-tradeoff"><i class="fa fa-check"></i>The Bias-Variance Tradeoff</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#the-test-train-split"><i class="fa fa-check"></i>The Test-Train Split</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#classification-methods"><i class="fa fa-check"></i>Classification Methods</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#discriminative-versus-generative-methods"><i class="fa fa-check"></i>Discriminative versus Generative Methods</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#parametric-and-non-parametric-methods"><i class="fa fa-check"></i>Parametric and Non-Parametric Methods</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#tuning-parameters"><i class="fa fa-check"></i>Tuning Parameters</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#cross-validation"><i class="fa fa-check"></i>Cross-Validation</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#curse-of-dimensionality"><i class="fa fa-check"></i>Curse of Dimensionality</a></li>
<li class="chapter" data-level="" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#no-free-lunch-theorem"><i class="fa fa-check"></i>No-Free-Lunch Theorem</a></li>
<li class="chapter" data-level="19.1" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#external-links-2"><i class="fa fa-check"></i><b>19.1</b> External Links</a></li>
<li class="chapter" data-level="19.2" data-path="supervised-learning-overview.html"><a href="supervised-learning-overview.html#rmarkdown-4"><i class="fa fa-check"></i><b>19.2</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="resampling.html"><a href="resampling.html"><i class="fa fa-check"></i><b>20</b> Resampling</a><ul>
<li class="chapter" data-level="20.1" data-path="resampling.html"><a href="resampling.html#test-train-split-1"><i class="fa fa-check"></i><b>20.1</b> Test-Train Split</a></li>
<li class="chapter" data-level="20.2" data-path="resampling.html"><a href="resampling.html#cross-validation-1"><i class="fa fa-check"></i><b>20.2</b> Cross-Validation</a><ul>
<li class="chapter" data-level="20.2.1" data-path="resampling.html"><a href="resampling.html#method-specific"><i class="fa fa-check"></i><b>20.2.1</b> Method Specific</a></li>
<li class="chapter" data-level="20.2.2" data-path="resampling.html"><a href="resampling.html#manual-cross-validation"><i class="fa fa-check"></i><b>20.2.2</b> Manual Cross-Validation</a></li>
<li class="chapter" data-level="20.2.3" data-path="resampling.html"><a href="resampling.html#test-data"><i class="fa fa-check"></i><b>20.2.3</b> Test Data</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="resampling.html"><a href="resampling.html#bootstrap"><i class="fa fa-check"></i><b>20.3</b> Bootstrap</a></li>
<li class="chapter" data-level="20.4" data-path="resampling.html"><a href="resampling.html#external-links-3"><i class="fa fa-check"></i><b>20.4</b> External Links</a></li>
<li class="chapter" data-level="20.5" data-path="resampling.html"><a href="resampling.html#rmarkdown-5"><i class="fa fa-check"></i><b>20.5</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="the-caret-package.html"><a href="the-caret-package.html"><i class="fa fa-check"></i><b>21</b> The <code>caret</code> Package</a><ul>
<li class="chapter" data-level="21.1" data-path="the-caret-package.html"><a href="the-caret-package.html#external-links-4"><i class="fa fa-check"></i><b>21.1</b> External Links</a></li>
<li class="chapter" data-level="21.2" data-path="the-caret-package.html"><a href="the-caret-package.html#rmarkdown-6"><i class="fa fa-check"></i><b>21.2</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="subset-selection.html"><a href="subset-selection.html"><i class="fa fa-check"></i><b>22</b> Subset Selection</a><ul>
<li class="chapter" data-level="22.1" data-path="subset-selection.html"><a href="subset-selection.html#aic-bic-and-cp"><i class="fa fa-check"></i><b>22.1</b> AIC, BIC, and Cp</a><ul>
<li class="chapter" data-level="22.1.1" data-path="subset-selection.html"><a href="subset-selection.html#leaps-package"><i class="fa fa-check"></i><b>22.1.1</b> <code>leaps</code> Package</a></li>
<li class="chapter" data-level="22.1.2" data-path="subset-selection.html"><a href="subset-selection.html#best-subset"><i class="fa fa-check"></i><b>22.1.2</b> Best Subset</a></li>
<li class="chapter" data-level="22.1.3" data-path="subset-selection.html"><a href="subset-selection.html#stepwise-methods"><i class="fa fa-check"></i><b>22.1.3</b> Stepwise Methods</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="subset-selection.html"><a href="subset-selection.html#validated-rmse"><i class="fa fa-check"></i><b>22.2</b> Validated RMSE</a></li>
<li class="chapter" data-level="22.3" data-path="subset-selection.html"><a href="subset-selection.html#external-links-5"><i class="fa fa-check"></i><b>22.3</b> External Links</a></li>
<li class="chapter" data-level="22.4" data-path="subset-selection.html"><a href="subset-selection.html#rmarkdown-7"><i class="fa fa-check"></i><b>22.4</b> RMarkdown</a></li>
</ul></li>
<li class="part"><span><b>VI The Modern Era</b></span></li>
<li class="chapter" data-level="23" data-path="modern-overview.html"><a href="modern-overview.html"><i class="fa fa-check"></i><b>23</b> Overview</a></li>
<li class="chapter" data-level="24" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>24</b> Regularization</a><ul>
<li class="chapter" data-level="24.1" data-path="regularization.html"><a href="regularization.html#ridge-regression"><i class="fa fa-check"></i><b>24.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="24.2" data-path="regularization.html"><a href="regularization.html#lasso"><i class="fa fa-check"></i><b>24.2</b> Lasso</a></li>
<li class="chapter" data-level="24.3" data-path="regularization.html"><a href="regularization.html#broom"><i class="fa fa-check"></i><b>24.3</b> <code>broom</code></a></li>
<li class="chapter" data-level="24.4" data-path="regularization.html"><a href="regularization.html#simulation-study-p-n"><i class="fa fa-check"></i><b>24.4</b> Simulation Study, p &gt; n</a></li>
<li class="chapter" data-level="24.5" data-path="regularization.html"><a href="regularization.html#external-links-6"><i class="fa fa-check"></i><b>24.5</b> External Links</a></li>
<li class="chapter" data-level="24.6" data-path="regularization.html"><a href="regularization.html#rmarkdown-8"><i class="fa fa-check"></i><b>24.6</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="elastic-net.html"><a href="elastic-net.html"><i class="fa fa-check"></i><b>25</b> Elastic Net</a><ul>
<li class="chapter" data-level="25.1" data-path="elastic-net.html"><a href="elastic-net.html#hitters-data"><i class="fa fa-check"></i><b>25.1</b> Hitters Data</a></li>
<li class="chapter" data-level="25.2" data-path="elastic-net.html"><a href="elastic-net.html#elastic-net-for-regression"><i class="fa fa-check"></i><b>25.2</b> Elastic Net for Regression</a></li>
<li class="chapter" data-level="25.3" data-path="elastic-net.html"><a href="elastic-net.html#elastic-net-for-classification"><i class="fa fa-check"></i><b>25.3</b> Elastic Net for Classification</a></li>
<li class="chapter" data-level="25.4" data-path="elastic-net.html"><a href="elastic-net.html#external-links-7"><i class="fa fa-check"></i><b>25.4</b> External Links</a></li>
<li class="chapter" data-level="25.5" data-path="elastic-net.html"><a href="elastic-net.html#rmarkdown-9"><i class="fa fa-check"></i><b>25.5</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="trees.html"><a href="trees.html"><i class="fa fa-check"></i><b>26</b> Trees</a><ul>
<li class="chapter" data-level="26.1" data-path="trees.html"><a href="trees.html#classification-trees"><i class="fa fa-check"></i><b>26.1</b> Classification Trees</a></li>
<li class="chapter" data-level="26.2" data-path="trees.html"><a href="trees.html#regression-trees"><i class="fa fa-check"></i><b>26.2</b> Regression Trees</a></li>
<li class="chapter" data-level="26.3" data-path="trees.html"><a href="trees.html#rpart-package"><i class="fa fa-check"></i><b>26.3</b> <code>rpart</code> Package</a></li>
<li class="chapter" data-level="26.4" data-path="trees.html"><a href="trees.html#external-links-8"><i class="fa fa-check"></i><b>26.4</b> External Links</a></li>
<li class="chapter" data-level="26.5" data-path="trees.html"><a href="trees.html#rmarkdown-10"><i class="fa fa-check"></i><b>26.5</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="ensemble-methods.html"><a href="ensemble-methods.html"><i class="fa fa-check"></i><b>27</b> Ensemble Methods</a><ul>
<li class="chapter" data-level="27.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#regression-1"><i class="fa fa-check"></i><b>27.1</b> Regression</a><ul>
<li class="chapter" data-level="27.1.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#tree-model"><i class="fa fa-check"></i><b>27.1.1</b> Tree Model</a></li>
<li class="chapter" data-level="27.1.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#linear-model"><i class="fa fa-check"></i><b>27.1.2</b> Linear Model</a></li>
<li class="chapter" data-level="27.1.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#bagging"><i class="fa fa-check"></i><b>27.1.3</b> Bagging</a></li>
<li class="chapter" data-level="27.1.4" data-path="ensemble-methods.html"><a href="ensemble-methods.html#random-forest"><i class="fa fa-check"></i><b>27.1.4</b> Random Forest</a></li>
<li class="chapter" data-level="27.1.5" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting"><i class="fa fa-check"></i><b>27.1.5</b> Boosting</a></li>
<li class="chapter" data-level="27.1.6" data-path="ensemble-methods.html"><a href="ensemble-methods.html#results"><i class="fa fa-check"></i><b>27.1.6</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="27.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#classification-1"><i class="fa fa-check"></i><b>27.2</b> Classification</a><ul>
<li class="chapter" data-level="27.2.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#tree-model-1"><i class="fa fa-check"></i><b>27.2.1</b> Tree Model</a></li>
<li class="chapter" data-level="27.2.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#logistic-regression-1"><i class="fa fa-check"></i><b>27.2.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="27.2.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#bagging-1"><i class="fa fa-check"></i><b>27.2.3</b> Bagging</a></li>
<li class="chapter" data-level="27.2.4" data-path="ensemble-methods.html"><a href="ensemble-methods.html#random-forest-1"><i class="fa fa-check"></i><b>27.2.4</b> Random Forest</a></li>
<li class="chapter" data-level="27.2.5" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting-1"><i class="fa fa-check"></i><b>27.2.5</b> Boosting</a></li>
<li class="chapter" data-level="27.2.6" data-path="ensemble-methods.html"><a href="ensemble-methods.html#results-1"><i class="fa fa-check"></i><b>27.2.6</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#tuning"><i class="fa fa-check"></i><b>27.3</b> Tuning</a><ul>
<li class="chapter" data-level="27.3.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#random-forest-and-bagging"><i class="fa fa-check"></i><b>27.3.1</b> Random Forest and Bagging</a></li>
<li class="chapter" data-level="27.3.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting-2"><i class="fa fa-check"></i><b>27.3.2</b> Boosting</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="ensemble-methods.html"><a href="ensemble-methods.html#tree-versus-ensemble-boundaries"><i class="fa fa-check"></i><b>27.4</b> Tree versus Ensemble Boundaries</a></li>
<li class="chapter" data-level="27.5" data-path="ensemble-methods.html"><a href="ensemble-methods.html#external-links-9"><i class="fa fa-check"></i><b>27.5</b> External Links</a></li>
<li class="chapter" data-level="27.6" data-path="ensemble-methods.html"><a href="ensemble-methods.html#rmarkdown-11"><i class="fa fa-check"></i><b>27.6</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="artificial-neural-networks.html"><a href="artificial-neural-networks.html"><i class="fa fa-check"></i><b>28</b> Artificial Neural Networks</a></li>
<li class="part"><span><b>VII Appendix</b></span></li>
<li class="chapter" data-level="29" data-path="appendix-overview.html"><a href="appendix-overview.html"><i class="fa fa-check"></i><b>29</b> Overview</a></li>
<li class="chapter" data-level="30" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>30</b> Non-Linear Models</a><ul>
<li class="chapter" data-level="30.1" data-path="non-linear-models.html"><a href="non-linear-models.html#polynomial-regression"><i class="fa fa-check"></i><b>30.1</b> Polynomial Regression</a><ul>
<li class="chapter" data-level="30.1.1" data-path="non-linear-models.html"><a href="non-linear-models.html#anova"><i class="fa fa-check"></i><b>30.1.1</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="non-linear-models.html"><a href="non-linear-models.html#logistic-regression-polynomial-terms"><i class="fa fa-check"></i><b>30.2</b> Logistic Regression, Polynomial Terms</a></li>
<li class="chapter" data-level="30.3" data-path="non-linear-models.html"><a href="non-linear-models.html#step-functions"><i class="fa fa-check"></i><b>30.3</b> Step Functions</a><ul>
<li class="chapter" data-level="30.3.1" data-path="non-linear-models.html"><a href="non-linear-models.html#smoothing-splines"><i class="fa fa-check"></i><b>30.3.1</b> Smoothing Splines</a></li>
</ul></li>
<li class="chapter" data-level="30.4" data-path="non-linear-models.html"><a href="non-linear-models.html#local-regression"><i class="fa fa-check"></i><b>30.4</b> Local Regression</a></li>
<li class="chapter" data-level="30.5" data-path="non-linear-models.html"><a href="non-linear-models.html#generalized-additive-models-gams"><i class="fa fa-check"></i><b>30.5</b> Generalized Additive Models (GAMs)</a><ul>
<li class="chapter" data-level="30.5.1" data-path="non-linear-models.html"><a href="non-linear-models.html#gams-in-caret"><i class="fa fa-check"></i><b>30.5.1</b> GAMs in <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="30.6" data-path="non-linear-models.html"><a href="non-linear-models.html#external-links-10"><i class="fa fa-check"></i><b>30.6</b> External Links</a></li>
<li class="chapter" data-level="30.7" data-path="non-linear-models.html"><a href="non-linear-models.html#rmarkdown-12"><i class="fa fa-check"></i><b>30.7</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html"><i class="fa fa-check"></i><b>31</b> Regularized Discriminant Analysis</a><ul>
<li class="chapter" data-level="31.1" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#sonar-data"><i class="fa fa-check"></i><b>31.1</b> Sonar Data</a></li>
<li class="chapter" data-level="31.2" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#rda"><i class="fa fa-check"></i><b>31.2</b> RDA</a></li>
<li class="chapter" data-level="31.3" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#rda-with-grid-search"><i class="fa fa-check"></i><b>31.3</b> RDA with Grid Search</a></li>
<li class="chapter" data-level="31.4" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#rda-with-random-search-search"><i class="fa fa-check"></i><b>31.4</b> RDA with Random Search Search</a></li>
<li class="chapter" data-level="31.5" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#comparison-to-elastic-net"><i class="fa fa-check"></i><b>31.5</b> Comparison to Elastic Net</a></li>
<li class="chapter" data-level="31.6" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#results-2"><i class="fa fa-check"></i><b>31.6</b> Results</a></li>
<li class="chapter" data-level="31.7" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#external-links-11"><i class="fa fa-check"></i><b>31.7</b> External Links</a></li>
<li class="chapter" data-level="31.8" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#rmarkdown-13"><i class="fa fa-check"></i><b>31.8</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>32</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="32.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#r-packages"><i class="fa fa-check"></i><b>32.1</b> <code>R</code> Packages</a></li>
<li class="chapter" data-level="32.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#classification-2"><i class="fa fa-check"></i><b>32.2</b> Classification</a></li>
<li class="chapter" data-level="32.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#linear-separable-example"><i class="fa fa-check"></i><b>32.3</b> Linear, Separable Example</a><ul>
<li class="chapter" data-level="32.3.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#data-simulation"><i class="fa fa-check"></i><b>32.3.1</b> Data Simulation</a></li>
<li class="chapter" data-level="32.3.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#linear-kernel-parameter-c"><i class="fa fa-check"></i><b>32.3.2</b> Linear Kernel, Parameter <code>C</code></a></li>
<li class="chapter" data-level="32.3.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#radial-kernel"><i class="fa fa-check"></i><b>32.3.3</b> Radial Kernel</a></li>
<li class="chapter" data-level="32.3.4" data-path="support-vector-machines.html"><a href="support-vector-machines.html#tuning-with-caret"><i class="fa fa-check"></i><b>32.3.4</b> Tuning with <code>caret</code></a></li>
<li class="chapter" data-level="32.3.5" data-path="support-vector-machines.html"><a href="support-vector-machines.html#compare-random-forest"><i class="fa fa-check"></i><b>32.3.5</b> Compare: Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="32.4" data-path="support-vector-machines.html"><a href="support-vector-machines.html#non-linear-non-separable-example"><i class="fa fa-check"></i><b>32.4</b> Non-Linear, Non-Separable Example</a><ul>
<li class="chapter" data-level="32.4.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#data-simulation-1"><i class="fa fa-check"></i><b>32.4.1</b> Data Simulation</a></li>
<li class="chapter" data-level="32.4.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#radial-kernel-parameter-c"><i class="fa fa-check"></i><b>32.4.2</b> Radial Kernel, Parameter <code>C</code></a></li>
<li class="chapter" data-level="32.4.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#radial-kernel-parameter-sigma"><i class="fa fa-check"></i><b>32.4.3</b> Radial Kernel, Parameter <code>sigma</code></a></li>
<li class="chapter" data-level="32.4.4" data-path="support-vector-machines.html"><a href="support-vector-machines.html#radial-kernel-tuning"><i class="fa fa-check"></i><b>32.4.4</b> Radial Kernel, Tuning</a></li>
<li class="chapter" data-level="32.4.5" data-path="support-vector-machines.html"><a href="support-vector-machines.html#polynomial-kernel-tuning"><i class="fa fa-check"></i><b>32.4.5</b> Polynomial Kernel, Tuning</a></li>
<li class="chapter" data-level="32.4.6" data-path="support-vector-machines.html"><a href="support-vector-machines.html#linear-kernel-tuning"><i class="fa fa-check"></i><b>32.4.6</b> Linear Kernel, Tuning</a></li>
<li class="chapter" data-level="32.4.7" data-path="support-vector-machines.html"><a href="support-vector-machines.html#compare-random-forest-1"><i class="fa fa-check"></i><b>32.4.7</b> Compare: Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="32.5" data-path="support-vector-machines.html"><a href="support-vector-machines.html#external-links-12"><i class="fa fa-check"></i><b>32.5</b> External Links</a></li>
<li class="chapter" data-level="32.6" data-path="support-vector-machines.html"><a href="support-vector-machines.html#rmarkdown-14"><i class="fa fa-check"></i><b>32.6</b> RMarkdown</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/daviddalpiaz/r4sl" target="blank">&copy; 2017 David Dalpiaz</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><code>R</code> for Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classification-overview" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Overview</h1>
<p><strong>Classification</strong> is a form of <strong>supervised learning</strong> where the response variable is categorical, as opposed to numeric for regression. <em>Our goal is to find a rule, algorithm, or function which takes as input a feature vector, and outputs a category which is the true category as often as possible.</em></p>
<div class="figure">
<img src="images/classification.png" alt="" />

</div>
<p>That is, the classifier <span class="math inline">\(\hat{C}\)</span> returns the predicted category <span class="math inline">\(\hat{y}\)</span>.</p>
<p><span class="math display">\[
\hat{y}_i = \hat{C}(\bf x_i)
\]</span></p>
<p>To build our first classifier, we will use the <code>Default</code> dataset from the <code>ISLR</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)
<span class="kw">library</span>(tibble)
<span class="kw">as_tibble</span>(Default)</code></pre></div>
<pre><code>## # A tibble: 10,000 x 4
##    default student   balance    income
##     &lt;fctr&gt;  &lt;fctr&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1      No      No  729.5265 44361.625
##  2      No     Yes  817.1804 12106.135
##  3      No      No 1073.5492 31767.139
##  4      No      No  529.2506 35704.494
##  5      No      No  785.6559 38463.496
##  6      No     Yes  919.5885  7491.559
##  7      No      No  825.5133 24905.227
##  8      No     Yes  808.6675 17600.451
##  9      No      No 1161.0579 37468.529
## 10      No      No    0.0000 29275.268
## # ... with 9,990 more rows</code></pre>
<p>Our goal is to properly classify individuals as defaulters based on student status, credit card balance, and income. Be aware that the response <code>default</code> is a factor, as is the predictor <code>student</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">is.factor</span>(Default$default)</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">is.factor</span>(Default$student)</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>As we did with regression, we test-train split our data. In this case, using 50% for each.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">42</span>)
train_index =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(Default), <span class="dv">5000</span>)
train_default =<span class="st"> </span>Default[train_index, ]
test_default =<span class="st"> </span>Default[-train_index, ]</code></pre></div>
<div id="visualization-for-classification" class="section level2">
<h2><span class="header-section-number">9.1</span> Visualization for Classification</h2>
<p>Often, some simple visualizations can suggest simple classification rules. To quickly create some useful visualizations, we use the <code>featurePlot()</code> function from the <code>caret()</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)</code></pre></div>
<p>A density plot can often suggest a simple split based on a numeric predictor. Essentially this plot graphs a density estimate</p>
<p><span class="math display">\[
f_{X_i}(x_i \mid y = k)
\]</span></p>
<p>for each numeric predictor <span class="math inline">\(x_i\)</span> and each category <span class="math inline">\(k\)</span> of the response <span class="math inline">\(y\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">featurePlot</span>(<span class="dt">x =</span> train_default[, <span class="kw">c</span>(<span class="st">&quot;balance&quot;</span>, <span class="st">&quot;income&quot;</span>)], 
            <span class="dt">y =</span> train_default$default,
            <span class="dt">plot =</span> <span class="st">&quot;density&quot;</span>, 
            <span class="dt">scales =</span> <span class="kw">list</span>(<span class="dt">x =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>), 
                          <span class="dt">y =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>)), 
            <span class="dt">adjust =</span> <span class="fl">1.5</span>, 
            <span class="dt">pch =</span> <span class="st">&quot;|&quot;</span>, 
            <span class="dt">layout =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>), 
            <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">2</span>))</code></pre></div>
<p><img src="09-classification_files/figure-html/unnamed-chunk-5-1.png" width="960" /></p>
<p>Some notes about the arguments to this function:</p>
<ul>
<li><code>x</code> is a data frame containing only <strong>numeric predictors</strong>. It would be nonsensical to estimate a density for a categorical predictor.</li>
<li><code>y</code> is the response variable. It needs to be a factor variable. If coded as <code>0</code> and <code>1</code>, you will need to coerce to factor for plotting.</li>
<li><code>plot</code> specifies the type of plot, here <code>density</code>.</li>
<li><code>scales</code> defines the scale of the axes for each plot. By default, the axis of each plot would be the same, which often is not useful, so the arguments here, a different axis for each plot, will almost always be used.</li>
<li><code>adjust</code> specifies the amount of smoothing used for the density estimate.</li>
<li><code>pch</code> specifies the <strong>p</strong>lot <strong>ch</strong>aracter used for the bottom of the plot.</li>
<li><code>layout</code> places the individual plots into rows and columns. For some odd reason, it is given as (col, row).</li>
<li><code>auto.key</code> defines the key at the top of the plot. The number of columns should be the number of categories.</li>
</ul>
<p>It seems that the income variable by itself is not particularly useful. However, there seems to be a big difference in default status at a <code>balance</code> of about 1400. We will use this information shortly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">featurePlot</span>(<span class="dt">x =</span> train_default[, <span class="kw">c</span>(<span class="st">&quot;balance&quot;</span>, <span class="st">&quot;income&quot;</span>)], 
            <span class="dt">y =</span> train_default$student,
            <span class="dt">plot =</span> <span class="st">&quot;density&quot;</span>, 
            <span class="dt">scales =</span> <span class="kw">list</span>(<span class="dt">x =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>), 
                          <span class="dt">y =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>)), 
            <span class="dt">adjust =</span> <span class="fl">1.5</span>, 
            <span class="dt">pch =</span> <span class="st">&quot;|&quot;</span>, 
            <span class="dt">layout =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>), 
            <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">2</span>))</code></pre></div>
<p><img src="09-classification_files/figure-html/unnamed-chunk-6-1.png" width="960" /></p>
<p>Above, we create a similar plot, except with <code>student</code> as the response. We see that students often carry a slightly larger balance, and have far lower income. This will be useful to know when making more complicated classifiers.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">featurePlot</span>(<span class="dt">x =</span> train_default[, <span class="kw">c</span>(<span class="st">&quot;student&quot;</span>, <span class="st">&quot;balance&quot;</span>, <span class="st">&quot;income&quot;</span>)], 
            <span class="dt">y =</span> train_default$default, 
            <span class="dt">plot =</span> <span class="st">&quot;pairs&quot;</span>,
            <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">2</span>))</code></pre></div>
<p><img src="09-classification_files/figure-html/unnamed-chunk-7-1.png" width="576" /></p>
<p>We can use <code>plot = &quot;pairs&quot;</code> to consider multiple variables at the same time. This plot reinforces using <code>balance</code> to create a classifier, and again shows that <code>income</code> seems not that useful.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ellipse)
<span class="kw">featurePlot</span>(<span class="dt">x =</span> train_default[, <span class="kw">c</span>(<span class="st">&quot;balance&quot;</span>, <span class="st">&quot;income&quot;</span>)], 
            <span class="dt">y =</span> train_default$default, 
            <span class="dt">plot =</span> <span class="st">&quot;ellipse&quot;</span>,
            <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">2</span>))</code></pre></div>
<p><img src="09-classification_files/figure-html/unnamed-chunk-8-1.png" width="576" /></p>
<p>Similar to <code>pairs</code> is a plot of type <code>ellipse</code>, which requires the <code>ellipse</code> package. Here we only use numeric predictors, as essentially we are assuming multivariate normality. The ellipses mark points of equal density. This will be useful later when discussing LDA and QDA.</p>
</div>
<div id="a-simple-classifier" class="section level2">
<h2><span class="header-section-number">9.2</span> A Simple Classifier</h2>
<p>A very simple classifier is a rule based on a boundary <span class="math inline">\(b\)</span> for a particular input variable <span class="math inline">\(x\)</span>.</p>
<p><span class="math display">\[
\hat{C}(\bf x) = 
\begin{cases} 
      1 &amp; x &gt; b \\
      0 &amp; x \leq b 
\end{cases}
\]</span></p>
<p>Based on the first plot, we believe we can use <code>balance</code> to create a reasonable classifier. In particular,</p>
<p><span class="math display">\[
\hat{C}(\text{balance}) = 
\begin{cases} 
      \text{Yes} &amp; \text{balance} &gt; 1400 \\
      \text{No} &amp; \text{balance} \leq 1400 
   \end{cases}
\]</span></p>
<p>So we predict an individual is a defaulter if their <code>balance</code> is above 1400, and not a defaulter if the balance is 1400 or less.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">simple_class =<span class="st"> </span>function(x, boundary, <span class="dt">above =</span> <span class="dv">1</span>, <span class="dt">below =</span> <span class="dv">0</span>) {
  <span class="kw">ifelse</span>(x &gt;<span class="st"> </span>boundary, above, below)
}</code></pre></div>
<p>We write a simple <code>R</code> function that compares a variable to a boundary, then use it to make predictions on the train and test sets with our chosen variable and boundary.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_pred =<span class="st"> </span><span class="kw">simple_class</span>(<span class="dt">x =</span> train_default$balance, 
                          <span class="dt">boundary =</span> <span class="dv">1400</span>, <span class="dt">above =</span> <span class="st">&quot;Yes&quot;</span>, <span class="dt">below =</span> <span class="st">&quot;No&quot;</span>)
test_pred =<span class="st"> </span><span class="kw">simple_class</span>(<span class="dt">x =</span> test_default$balance, 
                         <span class="dt">boundary =</span> <span class="dv">1400</span>, <span class="dt">above =</span> <span class="st">&quot;Yes&quot;</span>, <span class="dt">below =</span> <span class="st">&quot;No&quot;</span>)
<span class="kw">head</span>(train_pred, <span class="dt">n =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>##  [1] &quot;No&quot;  &quot;Yes&quot; &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;</code></pre>
</div>
<div id="metrics-for-classification" class="section level2">
<h2><span class="header-section-number">9.3</span> Metrics for Classification</h2>
<p>In the classification setting, there are a large number of metrics to asses how well a classifier is performing.</p>
<p>One of the most obvious things to do is arrange predictions and true values in a cross table.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="dt">train_tab =</span> <span class="kw">table</span>(<span class="dt">predicted =</span> train_pred, <span class="dt">actual =</span> train_default$default))</code></pre></div>
<pre><code>##          actual
## predicted   No  Yes
##       No  4319   29
##       Yes  513  139</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="dt">test_tab =</span> <span class="kw">table</span>(<span class="dt">predicted =</span> test_pred, <span class="dt">actual =</span> test_default$default))</code></pre></div>
<pre><code>##          actual
## predicted   No  Yes
##       No  4361   23
##       Yes  474  142</code></pre>
<p>Often we give specific names to individual cells of these tables, and in the predictive setting, we would call this table a <a href="https://en.wikipedia.org/wiki/Confusion_matrix"><strong>confusion matrix</strong></a>. Be aware, that the placement of Actual and Predicted values affects the names of the cells, and often the matrix may be presented transposed.</p>
<p>In statistics, we label the errors Type I and Type II, but these are hard to remember. False Positive and False Negative are more descriptive, so we choose to use these.</p>
<div class="figure">
<img src="images/confusion.png" alt="" />

</div>
<p>The <code>confusionMatrix()</code> function from the <code>caret</code> package can be used to obtain a wealth of additional information, which we see output below for the test data. Note that we specify which category is considered â€œpositive.â€</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_con_mat =<span class="st"> </span><span class="kw">confusionMatrix</span>(train_tab, <span class="dt">positive =</span> <span class="st">&quot;Yes&quot;</span>)
(<span class="dt">test_con_mat =</span> <span class="kw">confusionMatrix</span>(test_tab, <span class="dt">positive =</span> <span class="st">&quot;Yes&quot;</span>))</code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##          actual
## predicted   No  Yes
##       No  4361   23
##       Yes  474  142
##                                          
##                Accuracy : 0.9006         
##                  95% CI : (0.892, 0.9088)
##     No Information Rate : 0.967          
##     P-Value [Acc &gt; NIR] : 1              
##                                          
##                   Kappa : 0.3287         
##  Mcnemar&#39;s Test P-Value : &lt;2e-16         
##                                          
##             Sensitivity : 0.8606         
##             Specificity : 0.9020         
##          Pos Pred Value : 0.2305         
##          Neg Pred Value : 0.9948         
##              Prevalence : 0.0330         
##          Detection Rate : 0.0284         
##    Detection Prevalence : 0.1232         
##       Balanced Accuracy : 0.8813         
##                                          
##        &#39;Positive&#39; Class : Yes            
## </code></pre>
<p>The most common, and most important metric is the <strong>classification accuracy</strong>.</p>
<p><span class="math display">\[
\text{Acc}(\hat{C}, \text{Data}) = \frac{1}{n}\sum_{i = 1}^{n}I(y_i = \hat{C}(\bf x_i))
\]</span></p>
<p>Here, <span class="math inline">\(I\)</span> is an indicator function, so we are essentially calculating the proportion of predicted classes that match the true class.</p>
<p><span class="math display">\[
I(y_i = \hat{C}(x)) = 
\begin{cases} 
  1 &amp; y_i = \hat{C}(x) \\
  0 &amp; y_i \neq \hat{C}(x) \\
\end{cases}
\]</span></p>
<p>It is also common to discuss the <strong>misclassification rate</strong>, or classification error, which is simply one minus the accuracy.</p>
<p>Like regression, we often split the data, and then consider Train Accuracy and Test Accuracy. Test Accuracy will be used as a measure of how well a classifier will work on unseen future data.</p>
<p><span class="math display">\[
\text{Acc}_{\text{Train}}(\hat{C}, \text{Train Data}) = \frac{1}{n_{Tr}}\sum_{i \in \text{Train}}^{}I(y_i = \hat{C}(\bf x_i))
\]</span></p>
<p><span class="math display">\[
\text{Acc}_{\text{Test}}(\hat{C}, \text{Test Data}) = \frac{1}{n_{Te}}\sum_{i \in \text{Test}}^{}I(y_i = \hat{C}(\bf x_i))
\]</span></p>
<p>These accuracy values are given by calling <code>confusionMatrix()</code>, or, if stored, can be accessed directly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_con_mat$overall[<span class="st">&quot;Accuracy&quot;</span>]</code></pre></div>
<pre><code>## Accuracy 
##   0.8916</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_con_mat$overall[<span class="st">&quot;Accuracy&quot;</span>]</code></pre></div>
<pre><code>## Accuracy 
##   0.9006</code></pre>
<p>Sometimes guarding against making certain errors, FP or FN, are more important than simply finding the best accuracy. Thus, sometimes we will consider <strong>sensitivity</strong> and <strong>specificity</strong>.</p>
<p><span class="math display">\[
\text{Sens} = \text{True Positive Rate} = \frac{\text{TP}}{\text{P}} = \frac{\text{TP}}{\text{TP + FN}}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_con_mat$byClass[<span class="st">&quot;Sensitivity&quot;</span>]</code></pre></div>
<pre><code>## Sensitivity 
##   0.8606061</code></pre>
<p><span class="math display">\[
\text{Spec} = \text{True Negative Rate} = \frac{\text{TN}}{\text{N}} = \frac{\text{TN}}{\text{TN + FP}}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_con_mat$byClass[<span class="st">&quot;Specificity&quot;</span>]</code></pre></div>
<pre><code>## Specificity 
##   0.9019648</code></pre>
<p>Like accuracy, these can easily be found using <code>confusionMatrix()</code>.</p>
<p>When considering how well a classifier is performing, often, it is understandable to assume that any accuracy in a binary classification problem above 0.50, is a reasonable classifier. This however is not the case. We need to consider the <strong>balance</strong> of the classes. To do so, we look at the <strong>prevalence</strong> of positive cases.</p>
<p><span class="math display">\[
\text{Prev} = \frac{\text{P}}{\text{Total Obs}}= \frac{\text{TP + FN}}{\text{Total Obs}}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_con_mat$byClass[<span class="st">&quot;Prevalence&quot;</span>]</code></pre></div>
<pre><code>## Prevalence 
##     0.0336</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_con_mat$byClass[<span class="st">&quot;Prevalence&quot;</span>]</code></pre></div>
<pre><code>## Prevalence 
##      0.033</code></pre>
<p>Here, we see an extremely low prevalence, which suggests an even simpler classifier than our current based on <code>balance</code>.</p>
<p><span class="math display">\[
\hat{C}(\text{balance}) = 
\begin{cases} 
      \text{No} &amp; \text{balance} &gt; 1400 \\
      \text{No} &amp; \text{balance} \leq 1400 
   \end{cases}
\]</span></p>
<p>This classifier simply classifies all observations as negative cases.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_all_no =<span class="st"> </span><span class="kw">simple_class</span>(test_default$balance, 
                           <span class="dt">boundary =</span> <span class="dv">1400</span>, <span class="dt">above =</span> <span class="st">&quot;No&quot;</span>, <span class="dt">below =</span> <span class="st">&quot;No&quot;</span>)
<span class="kw">table</span>(<span class="dt">predicted =</span> pred_all_no, <span class="dt">actual =</span> test_default$default)</code></pre></div>
<pre><code>##          actual
## predicted   No  Yes
##        No 4835  165</code></pre>
<p>The <code>confusionMatrix()</code> function wonâ€™t even accept this table as input, because it isnâ€™t a full matrix, only one row, so we calculate some metrics â€œby handâ€.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">4835</span> /<span class="st"> </span>(<span class="dv">4835</span> +<span class="st"> </span><span class="dv">165</span>) <span class="co"># test accuracy</span></code></pre></div>
<pre><code>## [1] 0.967</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> -<span class="st"> </span><span class="fl">0.0336</span> <span class="co"># 1 - (train prevelence)</span></code></pre></div>
<pre><code>## [1] 0.9664</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> -<span class="st"> </span><span class="fl">0.033</span> <span class="co"># 1 - (test prevelence)</span></code></pre></div>
<pre><code>## [1] 0.967</code></pre>
<p>This classifier does better than the previous. But the point is, in reality, to create a good classifier, we should obtain a test accuracy better than 0.967, which is obtained by simply manipulating the prevalence. Next chapter, weâ€™ll introduce much better classifiers which should have no problem accomplishing this task.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="simulating-the-biasvariance-tradeoff.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="logistic-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/daviddalpiaz/r4sl/edit/master/09-classification.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
